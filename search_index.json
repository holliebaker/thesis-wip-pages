[["index.html", "Thesis Chapter 1 Cylindrical algebraic decompositions with monotone cells", " Thesis Hollie 2024-01-08 Chapter 1 Cylindrical algebraic decompositions with monotone cells A Cylindrical Algebraic Decomposition (CAD) is a finite partition of n-dimensional space into so-called Cylindrical Cells. The key idea of cylindricity is that cells are arranged in stacks. I.e., the projection of any two cells onto dimension n-1 is either disjoint or identical. CAD provides a constructive and computationally tractable proof of the famous Tarski-Seidenberg theorem, which states that semialgebraic sets are closed under projection, or, equivalently, that quantifier elimination is possible over the reals. Indeed, QE is possibly the most famous application of CAD. CAD also has applications in computing topological properties of semialgebraic sets and solving motion-planninng problems. However, for these applications, a basic CAD will not suffice. Instead, we may have to introduce some additional constraints to the construction. One such constraint, which is useful in topology, is that every cell in the CAD is a topologically regular cell. Put briefly, its boundary should be homeomorphic to a circle. Another useful property is the frontier condition. I.e., the boundary of every cell in the decomposition must be a union of some other cells in the decomposition of smaller dimension. This property is necessary to solve motion planning problems. The goal of this thesis is to develop an algorithm to construct such a CAD. In fact, a CAD satisfying a slightly stronger condition – such that every cell contained in some input set in monotone. It has been proved that a monotone cell is a topologically regular cell. The constructive proof that such a CAD exists is due to (Basu, Gabrielov, and Vorobjov 2015), and this thesis will aim to extract an algorithm from the formal description. (Basu, Gabrielov, and Vorobjov 2015) work over the category of sub-pfaffian sets, using an algorithm due to TODO to construct the base cylindrical decomposition. However, the algorithm presented here will work with semialgebraic sets, using the more familiar CAD due to (???). This will allow the tools of computer algobra to be used. In addition, an implementation would not be possible over sub-pfaffian sets, as an oracle is needed to determine whether a set is empty. References "],["1.1-things-to-explain.html", "1.1 Things to explain", " 1.1 Things to explain some background on CAD algorithms (including pfaffian one), implementations and upper bounds monotone cells are obtained by refinements, i.e., more cells why might one want to introduce more cells? "],["2-bits-and-pieces.html", "Chapter 2 Bits and Pieces ", " Chapter 2 Bits and Pieces "],["2.1-definitions-that-dont-quite-fit-anywhere-else..html", "2.1 Definitions that don’t quite fit anywhere else.", " 2.1 Definitions that don’t quite fit anywhere else. Definition 2.1 A structure expanding the real closed field \\(R\\) is a collection \\[ S := (S^n)_{n \\in \\mathbb{N}} \\] where each \\(S^n\\) is a set of subsets of the affine space \\(R^n\\) satisfying the following conditions. All algebraic subsets of \\(R^n\\) are in \\(S^n\\). \\(S^n\\) is a Boolean subalgebra of the powerset of \\(R^n\\). If \\(A \\in S^n\\) and \\(B \\in S^m\\), then \\(A \\times B \\in S^{n+m}\\). Let \\(\\operatorname{proj}: R^{n+1} \\to R\\) be the projection onto the first \\(n\\) coordinates. If \\(X\\in R^{n+1}\\), then \\(\\operatorname{proj}(X) \\in R^n\\). Definition 2.2 A structure \\(S\\) satisfying the properties of a definable set (listed in Definition 2.1) and The elements of \\(S^1\\) consist of the finite unions of points and open intervals of \\(R\\). We work in the category of Semialgebraic sets over the real closed field \\(\\mathbb{R}\\). Semialgebraic sets are, perhaps, the most well-known example of an o-minimal structure. Definition 2.3 A map \\(f : A \\to R^m\\), where \\(A \\subset R^n\\), is called definable if its graph \\(G \\subset R^{n+m}\\) is a definable set. Remark. Since definable sets are closed under projection, it can be easily deduced that \\(A\\) is a definable set. Remark. For convenience, we will call a definable map \\(f : R^n \\to R\\) a definable function. "],["2.2-definition-of-the-cad.html", "2.2 Definition of the CAD", " 2.2 Definition of the CAD Projection to the induced decomposition vs construction of stacks above cylindrical cells. … A section cell \\(C\\) is the graph, in \\(\\mathbb{R}^n\\), of a continuous definable function \\(h : C&#39; \\to \\mathbb{R}\\), where \\(C&#39;\\) is a cylindrical cell in \\(\\mathbb{R}^{n-1}\\). In reality, we are given a set of level-\\(n\\) projection factors and \\(C\\) is a real root of a polynomial \\(f \\in \\mathbb{Z}[x_1,\\ldots,x_n]\\), viewed as a polynomial in \\(\\mathbb{Z}[x_1,\\ldots,x_{n-1}][x_n]\\). By the construction of CAD, \\(f\\) has \\(k\\) real roots at every point \\(\\mathbf{c} \\in C&#39;\\). In some situations, the former representation (with functions) is more convenient (than the latter, with roots). Observe that it is easy to convert from the function representation to the root representation. Indeed, let \\(C\\subset R^{n}\\) be the graph of \\[h : C&#39; \\to \\mathbb{R}\\] where \\(C&#39; \\subset \\mathbb{R}^{n-1}\\) is an \\((i_1,\\ldots,i_{n-1})\\)-cell in \\(\\mathbb{R}^{n-1}\\). For every \\(\\mathbf{c} \\in C&#39;\\), the graph \\(C\\) can be written as a root of \\[ f := h(\\mathbf{c}) - x_n \\in Z[x_1,\\ldots,x_n] \\] The specific root of \\(f\\) such that \\(x_n = h(\\mathbf{c})\\) can be isolated, by Thom’s lemma, by adding some sign conditions on partial derivatives of \\(g\\). Now let \\(f \\in \\mathbb{Z}[x_1,\\ldots,x_{n-1}][x_n]\\) be a polynomial in \\(x_n\\) and \\(C&#39; \\subset \\mathbb{R}^{n-1}\\) be a \\((i_1,\\ldots,i_{n-1})\\)-cell of \\(\\mathbb{R}^{n-1}\\). Then the cylinder \\(C&#39; \\times \\mathbb{R}\\) (“above” \\(C&#39;\\)) contains a family of section cells \\[ {\\cal C} := \\{ (\\mathbf{c},x_n) \\mid \\mathbf{c} \\in C&#39;, f(\\mathbf{c},x_n) = 0 \\}. \\] The family \\(\\cal C\\) consists of \\(k\\) connected semialgebraic sets, corresponding to the \\(k\\) section cells on which \\(f = 0\\). Suppose we want to represent one of these section cells \\(C \\in {\\cal C}\\) as the graph of \\(h : C&#39; \\to \\mathbb{R}\\). By Thom’s lemma, we can write \\[ C = \\{ (\\mathbf{c},x_n) \\mid \\mathbf{c} \\in C&#39;, f(\\mathbf{c},x_n) = 0, g_1(\\mathbf{c},x_n) &gt; 0, \\ldots, g_k(\\mathbf{c},x_n) \\} \\] where \\(g_1,\\ldots,g_k\\) are partial derivatives of \\(f\\). \\(C\\) is a semialgebraic set, therefore \\(h\\) is certainly a definable function. But, is \\(h\\) a polynomial? The answer is no. This can be seen using a simple example. Example 2.1 Let \\(D \\subset \\mathbb{R}^2\\) be the unit disc, a semialgebraic set defined by a quantifier-free Boolean formula \\[ \\{ x^2 + y^2 &lt; 1 \\}. \\] Construct a CAD of \\(\\mathbb{R}^2\\) compatible with \\(D\\) in which \\(D\\) is a single sector cell. Observe that the top of \\(D\\), \\[ D_T = \\{ -1 &lt; x &lt; 1, y &gt; 0, x^2 + y^2 = 0 \\} \\] and \\[ D&#39; := {\\operatorname{proj}_{\\mathbb{R}^{1}}}(D) = \\{ -1 &lt; x &lt; 1 \\}. \\] It is clear that \\(D_T\\) is a semialgebraic (and therefore a definable) set, so there exists a definable function \\[ h : D&#39; \\to \\mathbb{R} \\] such that \\(D_T\\) is the graph of \\(h\\vert_{D&#39;}\\). Indeed, let \\[ h(x) = +\\sqrt{1-x^2}. \\] This is clearly not a polynomial. In addition, it’s clear that not every definable set is the graph of a definable map. Indeed, consider \\[ C := \\{ x^2 + y^2 = 1 \\} \\] and \\[ C&#39; := {\\operatorname{proj}_{\\mathbb{R}^{1}}}(C) = \\{ -1 \\le x \\le 1 \\}. \\] Both \\(C\\) and \\(C&#39;\\) are clearly definable, but there is no map from \\(C&#39; \\to \\mathbb{R}\\) having \\(C\\) as its graph. Indeed, at \\(x=0\\), this map should have images \\(-1\\) and \\(1\\), which contradicts the definition of a map. However, in the case of a cylindrical section cell, the map \\(h\\) always exists by definition. Therefore, when working with cylindrical section cells, the map \\(h : C&#39; \\to \\mathbb{R}\\) may be used, but algorithms will work solely with polynomials \\(f \\in \\mathbb{Z}{x_1,\\ldots,x_{n-1}}[x_n]\\) from the level-\\(n\\) projection factor set. "],["3-background-cad.html", "Chapter 3 Background: CAD", " Chapter 3 Background: CAD Collins (1975) introduced both the concept of cylindrical algebraic decomposition and an algorithm to construct one, such that each cell has constant sign on a set of input polynomials. First, we will present the formal definition of a cylindrical cell and cylindrical decomposition, closely following Basu, Gabrielov, and Vorobjov (2015) and then explain how a cylindrical decomposition can be constructed (following Coste (2000), who presents a simple and concise description). Cylindrical cells are defined by induction on \\(n\\ge 1\\). Each cylindrical cell \\(C\\) is a connected definable subset of \\(\\mathbb{R}^n\\) with an index \\[ (i_1,\\ldots,i_n) \\in \\{0,1\\}^n. \\] When \\(n = 1\\), a \\((0)\\)-cell (section cell) is a point \\(c \\in \\mathbb{R}\\) and a \\((1)\\)-cell (sector cell) is an open interval: \\((a,b)\\), \\((-\\infty,b)\\), \\((a,\\infty)\\), \\((-\\infty,\\infty)\\) where \\(a,b\\in \\mathbb{R}\\). When \\(n &gt; 1\\), suppose that \\((i_1,\\ldots,i_{n-1})\\)-cells are already defined and let \\(C&#39;\\) be one of these cells. An \\((i_1,\\ldots,i_{n-1},0)\\)-cell (section cell) is the graph of a continuous definable function \\(f : C&#39; \\to \\mathbb{R}\\). An - \\((i_1,\\ldots,i_{n-1},1)\\)-cell (sector cell) is a subset of the cylinder \\(C&#39; \\times \\mathbb{R}\\), either \\[ \\begin{aligned} \\{ (\\mathbf{x},t) &amp;\\mid \\mathbf{x} \\in C&#39;, f(\\mathbf{x}) &lt; t &lt; g(\\mathbf{x})\\},\\\\ \\{ (\\mathbf{x},t) &amp;\\mid \\mathbf{x} \\in C&#39;, -\\infty &lt; t &lt; g(\\mathbf{x})\\},\\\\ \\{ (\\mathbf{x},t) &amp;\\mid \\mathbf{x} \\in C&#39;, f(\\mathbf{x}) &lt; t &lt; \\infty\\},\\\\ \\{ (\\mathbf{x},t) &amp;\\mid \\mathbf{x} \\in C&#39;, t \\in \\mathbb{R}\\} \\end{aligned} \\] where \\(f,g : C&#39; \\to \\mathbb{R}\\) are continuous definable functions such that \\(f(\\mathbf{x}) &lt; g(\\mathbf{x})\\) for all \\(\\mathbf{x} \\in C&#39;\\). Let \\(S \\subset \\mathbb{R}^n\\) be a definable subset of \\(\\mathbb{R}^n\\) and define the frontier of \\(S\\) \\[ \\fr(S) := {\\operatorname{cl} \\left( ( \\right)}S) \\setminus S, \\] where \\({\\operatorname{cl} \\left( ( \\right)}S)\\) is the closure of \\(S\\) in euclidean topology. If \\(C \\subset \\mathbb{R}^n\\) is a cylinrical cell, then it will be convenient to partition \\(\\fr(C)\\) into three subsets: the top (denoted \\(C_t\\)), bottom (denoted \\(C_B\\)) and side wall (denoted \\(C_W\\)). First suppose that \\(C\\) is a sector \\((i,1,\\ldots,i_{n-1},1)\\)-cell and let \\(C&#39; := {\\operatorname{proj}_{\\mathbb{R}^{n-1}}}(C)\\). If \\(C\\) is bounded from below by a continuous function \\(f : C&#39; \\to \\mathbb{R}\\), then \\(C_B\\) is the graph of \\(f\\). Similarly, if \\(C\\) is bounded from above by the graph of a continuous function \\(g : C&#39; \\to \\mathbb{R}\\), then \\(C_T\\) is the graph of \\(g\\). It is clear that the top and bottom of a cylindrical sector cell (if non-empty) are alwyas cylindrical section cells. Now let \\(C\\) be an \\((i_1,\\ldots,i_{k},0,\\ldots,0)\\)-cell, where \\(i_{k}=1\\), and \\(C&#39; := {\\operatorname{proj}_{\\mathbb{R}^{k}}}(C)\\). Since \\(C&#39;\\) is a sector cell, \\(C&#39;_B\\) and \\(C&#39;_T\\) are cylindrical section cells. The bottom \\(C_B\\) of \\(C\\) is the pre-image of \\(C&#39;_B\\) by the projection map \\({\\operatorname{proj}_{\\mathbb{R}^{k}}}\\vert_{{\\operatorname{cl} \\left( ( \\right)}C)}\\) and the top \\(C_T\\) of \\(C\\) is the pre-image of \\(C&#39;_T\\) by the projection map \\({\\operatorname{proj}_{\\mathbb{R}^{k-1}}}\\vert_{{\\operatorname{cl} \\left( ( \\right)}C)}\\). Instead of pre-images, it might be simpler to think of \\(C_B\\) as the semialgebraic set \\({\\operatorname{cl} \\left( ( \\right)}C) \\cap (C&#39;_B \\times \\mathbb{R}^{n - k + 1})\\) and \\(C_T\\) as the semialgebraic set \\({\\operatorname{cl} \\left( ( \\right)}C) \\cap (C&#39;_T \\times \\mathbb{R}^{n - k + 1})\\). Note that \\(C_B\\) and \\(C_T\\) may not be cylindrical cells. Indeed, they may fail to be graphs of continuous functions (see Example TODO). For both section and sector cells, let the side wall, \\(C_W\\), be \\({\\operatorname{cl} \\left( ( \\right)}C) \\setminus (C_B \\cup C_T)\\). Of course, there is no gaurantee at all that \\(C_W\\) will be (a union of) cylindrical cells. A cylindrical decomposition (not necessarily algebraic) is defined by induction on \\(n \\ge 0\\). When \\(n = 0\\), the unique cylindrical decomposition of \\(\\mathbb{R}^0\\) is the unique point in \\(\\mathbb{R}^0\\). When \\(n &gt; 0\\): Let \\(\\cal D\\) be a partition of \\(\\mathbb{R}^n\\) into cylindrical cells. Define \\(\\cal D&#39;\\) to be the set of all projections \\(C&#39; := {\\operatorname{proj}_{\\mathbb{R}^{n-1}}}(C)\\) for all \\(C\\) in \\(\\cal D\\). \\(\\cal D\\) is a cylindrical decomposition of \\(\\mathbb{R}^n\\) if \\(\\cal D&#39;\\) is a cylindrical decomposition of \\(\\mathbb{R}^{n-1}\\). We call \\(\\cal D&#39;\\) the *decomposion of \\(\\mathbb{R}^{n-1}\\) induced by \\(\\cal D\\). Less formally, a decomposition \\(\\cal D\\) of \\(\\mathbb{R}^n\\) is cylindrical if the projection of any two cells of \\(\\cal D\\) onto \\(\\mathbb{R}^{n-1}\\) is either disjoint or coincides. maybe move this to just before the coste bit ::: {.remark} A cylindrical decomposition is called algebraic if every cell is a semialgebraic set. We will only be working with cylindrical algebraic decompositions (CADs). ::: Definition 3.1 Let \\(S \\subset \\mathbb{R}^n\\) be a definable set. A cylindrical decomposition \\(\\cal D\\) is compatible with \\(S\\) if every cell \\(C\\) of \\(\\cal D\\) is either a subset of \\(S\\) or disjoint from \\(S\\). — {.definition} A cylindrical decomposition \\(\\cal E\\) is called a refinement of \\(\\cal D\\) if \\(\\cal E\\) is compatible with every cell of \\(\\cal D\\). I.e., every cell of \\(\\cal D\\) is a union of cells in the refinement \\(\\cal E\\). —- Definition 3.2 Let \\(\\mathbf{F} := (f_1,\\ldots,f_s) \\subset \\mathbb{Z}[x_1,\\ldots,x_n]\\) be a set of polynomials with integer coefficients. A CAD \\(\\cal D\\) is called sign-invariant with respect to \\(\\mathbf{F}\\) (or \\(\\mathbf{F}\\)-invariant) if every cell \\(C\\) of \\(\\cal D\\) has constant sign (either \\(&gt; 0\\), \\(&lt; 0\\) or \\(= 0\\)) on every polynomial in \\(\\mathbf{F}\\). (Here \\(\\mathbf{F}\\) is called the set of input polynomials.) 3.0.1 Constructing a CAD Let \\(\\mathbf{F} \\subset \\mathbb{Z}[x_1,\\ldots,x_n]\\) be a set of polynomials with integer coefficients. We will now describe the algorithm due to Collins (1975) for constructing an \\(\\mathbf{F}\\)-invariant CAD of \\(\\mathbb{R}^n\\). Let us begin with just one polynomial \\(f \\in \\mathbb{Z}[x_1,\\ldots,x_n]\\). We want to partition \\(\\mathbb{R}^{n-1}\\) into connected semialgebraic sets \\(C&#39;\\) such that, for all $ C’ $,, \\(f(\\mathbf{x},x_n)\\) has constant degree and a constant number of roots. Thus, the roots of \\(f(\\mathbf{x},x_n\\) form the section cells of the cylinder \\(C&#39; \\times \\mathbb{R}\\). Let \\(f \\in \\mathbb{Z}[x_1,\\ldots,x_n]\\) be a polynomial in \\(n\\) variables with integer coefficients, \\(C&#39; \\subset \\mathbb{R}^{n-1}\\) be a connected semialgebraic set and \\(k \\le d \\in \\mathbb{N}\\) such that, for every point \\(\\mathbf{x} \\in C&#39;\\), the univariate polynomial \\(f(\\mathbf{x},x_n) \\in \\mathbb{A}[x_n]\\) has degree \\(d\\) and exactly \\(k\\) distinct (complex) roots in \\(C&#39;\\). Then Then there are \\(\\ell \\le k\\) distinct definable functions \\(\\psi_1,\\ldots,\\psi_\\ell : C&#39; \\to \\mathbb{R}\\) such that, for every \\(\\mathbf{x} \\in C&#39;\\), the set of real roots of \\(f(\\mathbf{x},x_n)\\) is exactly \\(\\{ \\psi_1(\\mathbf{x}, \\ldots, \\psi_\\ell(\\mathbf{x}) \\}\\). Moreover, the multiplicity of each of each root is constant. Proof. The argument relies on the “continuity of roots”: Fix \\(\\mathbf{c} \\in C&#39;\\) and let \\(z_1,\\ldots,z_k\\) be the distinct roots of \\(f(\\mathbf{c},x_n)\\) with multiplicities \\(m_1,\\ldots,m_k\\). Choose \\(\\varepsilon &gt; 0\\) small enough that the open discs \\(D(z_i,\\varepsilon) z_i \\subset \\mathbb{C}\\) (center \\(z_i\\), radius $) are disjoint. If \\(\\mathbf{b} \\in C\\) is sufficiently close to \\(\\mathbf{c}\\), then the polynomial \\(f(\\mathbf{b}, x_n)\\) has exactly \\(m_i\\) roots, counted with multiplicities, in \\(D(z_i,\\varepsilon)\\) for \\(1\\le i \\le k\\). Since \\(f(\\mathbf{b},x_n)\\) has k distinct complex roots, and \\(d = m_1,\\ldots,m_k\\) complex roots counted with multiplicities, it follows that each \\(D(z_i,\\varepsilon)\\) contains exactly one root, call it \\(\\zeta_i\\), of \\(f(\\mathbf{b},x_n)\\) with multiplicity \\(m_i\\). If \\(z_i\\) is real, then \\(\\zeta_i\\) is real, otherwise the complex conjugate of \\(\\zeta_i\\) would be another root of \\(f(\\mathbf{b},x_n)\\) in the disc \\(D(Z-i,\\varepsilon)\\). If \\(z_i\\) is complex then \\(\\zeta_i\\) is also complex, since the conjugation of every point in \\(D(z_i, \\varepsilon)\\) lies outside \\(D(z_i, \\varepsilon)\\), forming another disc \\(D(\\overline{z_i}, \\varepsilon)\\). It follows that, if \\(\\mathbf{b} \\in C&#39;\\) is close enough to \\(\\mathbf{c}\\), then \\(f(\\mathbf{c},x_n)\\) has the same number of real roots as \\(f(\\mathbf{c},x_n)\\). Since \\(C&#39;\\) is connected, \\(f(\\mathbf{x},x_n)\\) has the same number of real roots at every point \\(\\mathbf{x} \\in C&#39;\\). Let the number of distinct real roots be \\(\\ell\\). Define \\(\\psi_i(\\mathbf{x}) : C&#39; \\to \\mathbb{R}\\) to be the continuous (by making \\(\\varepsilon\\) small enough) definable function sending \\(\\mathbf{x} \\in C&#39;\\) to the \\(i\\)-th (in ascending order) real root of \\(f(\\mathbf{x},x_n)\\). It follows from the connectedness of \\(C&#39;\\) that each \\(\\psi_i\\) has constant multiplicity. Observe that the graph of each \\(\\psi_i\\) can be expressed by a first-order Boolean formula (using existential quantifiers to express each of the \\(\\ell\\) roots of \\(f(\\mathbf{x},x_n)\\), and an equality condition to pick out the \\(i\\)-th root). It follows that the graph of each \\(\\psi_i\\) is a semialgebraic set. To extend this result to several polynomials, we have to be careful that the graphs corresponding to the roots of the polynomials do not cross one another. This gives us the property that \\(\\psi_i(\\mathbf{x}) &lt; \\psi_{i+1}(\\mathbf{x})\\) for all \\(\\mathbf{x} \\in C&#39;\\) which is needed for the cylindrical structure. This property is called delineability. Proposition 3.1 Let \\(f,g \\in \\mathbb{Z}[x_1,\\ldots,x_n]\\), \\(C&#39; \\subset \\mathbb{R}^{n-1}\\) such that the degree and number of roots of \\(f(\\mathbf{x},x_n)\\) and \\(g(\\mathbf{x},x_n)\\) is constant, and the degree of the GCD of \\(f(\\mathbf{x},x_n)\\) and \\(g(\\mathbf{x},x_n)\\) is constant for all \\(\\mathbf{x} \\in C&#39;\\). Let \\(\\phi,\\psi : C&#39; \\to \\mathbb{R}\\) be continuous definable functions such that \\(f(\\mathbf{x},\\phi(\\mathbf{x})) = 0\\) and \\(g(\\mathbf{x},\\psi(\\mathbf{x})) = 0\\) for all \\(\\mathbf{x} in C&#39;\\). If there exists \\(\\mathbf{c} \\in C&#39;\\) such that \\(\\phi(\\mathbf{c}) = \\psi(\\mathbf{c})\\), then \\(\\phi(\\mathbf{x}) = \\psi(\\mathbf{x})\\) for all \\(\\mathbf{x} \\in C&#39;\\). Proof. We use the same method of proof as in the previous proposition. For an arbitrary element \\(\\mathbf{c} of C&#39;\\), let \\(z_1 = \\phi(\\mathbf{c}) = \\psi(\\mathbf{x}), \\ldots, z_k\\) be the distinct roots in \\(\\mathbb{C}\\) of the product \\[ f(\\mathbf{c},x_n) g(\\mathbf{c},x_n) \\] (\\(fg = 0\\) if either \\(f=0\\) or \\(g=0\\)). Let \\(m_i\\) (resp \\(p_i\\)) be the multiplicity of \\(z_i\\) as a root of \\(f(\\mathbf{x},x_n)\\) (resp. \\(g(\\mathbf{x}, x_n)\\)) where multiplicity zero indicates that \\(z_i\\) is not a root. Thedegree of \\(gcd(f(\\mathbf{x}, x_n), g(\\mathbf{x}, x_n))\\) is \\(\\min(m_1,p_1) + \\cdots + \\min(m_k,p_k)\\) and each \\(z_i\\) has multiplicity \\(\\min(m_i,p_i)\\) as a root of this GCD. Choose \\(\\varepsilon &gt; 0\\) small enough that the discs \\(D(z_i,\\varepsilon)\\) are disjoint. For each \\(\\mathbf{b} \\in C&#39;\\) close enough to \\(\\mathbf{c}\\), each disc contains a root of multiplicity \\(m_i\\) of \\(f(\\mathbf{b}, x_n)\\) and a root of multiplicity \\(p_i\\) of \\(g(\\mathbf{b}, x_n)\\). Since the degree of the GCD of \\(f\\) and \\(g\\) (evaluated at any \\(\\mathbf{x}\\) in \\(C&#39;\\)) is equal to \\(\\min(m_1,p_1) + \\cdots + \\min(m_k,p_k)\\), the GCD must have one root of multiplicity \\(\\min(m_i,p_i)\\) in each disc \\(D(z_i,\\varepsilon)\\) such that \\(\\min(m_i,p_i) &gt; 0\\). In particular, it follows that \\(\\phi(\\mathbf{b}) = \\psi(\\mathbf{b})\\). Since \\(C\\) is connected, this equality holds for all \\(\\mathbf{x} \\in C&#39;\\). We now have algebraic conditions on properties of the polynomials in \\(\\mathbf{F}\\) which allow us to construct stacks above cylindrical cells \\(C&#39; \\subset \\mathbb{R}^{n-1}\\). We can ensure that these conditions on polynomials hold by computing principal subresultant coefficients. more precisely \\(f\\) has a fixed number of complex roots over a set where \\(\\operatorna{psrc}_i(f,f&#39;)\\) is either zero or nonzero and \\(f\\) and \\(g\\) has constant GCD over a when \\(\\operatorna{psrc}_i(f, g)\\) is either zero or nonzero, as long as the degrees of \\(f\\) and \\(g\\) are fixed. In the case that, for some values of \\()x_1,\\ldots,x_n) \\in \\mathbb{R}^{n-1}\\) the leading coefficients of \\(f\\) and \\(g\\) vanish, we must use the principal subresultant coefficients of the reductum (also called truncated polynomial, obtained by deleting the leading term) of \\(f\\) and \\(g\\). Definition 3.3 Consider \\(f \\in \\mathbb{Z}[x_1,\\ldots,x_n]\\) as a univariate polynomial in \\(x_n\\) with coefficients in \\(\\mathbb{Z}[x_1,\\ldots,x_{n-1}]\\). Denote by \\(\\operatorna{lc}{f}\\) the leading coefficient of \\(f\\), and \\(\\operatorna{red}(f}\\) the reductum of \\(f\\). Let \\(\\mathbf{f} \\subset \\mathbb{Z}[x_1,\\ldots,x_n]\\). We define the projection operator, \\(\\operatorname{proj}(\\mathbf{F})\\) as follows: Let \\(d := \\deg(f_i)\\). If \\(d &gt; 1\\), then \\(\\operatorname{proj}(f_1,\\ldots,f_i,\\ldots,f_s)\\) contains \\[ \\operatorna{psrc}_k(f_i, \\partial f_i / \\partial x_n) \\] for all \\(1\\le k \\le d\\). Let \\(d := \\min(\\deg(f_i), \\deg(f_j))\\). If \\(d &gt; 0\\), then \\(\\operatorname{proj}(f_1,\\ldots,f_i,\\ldots,f_j,\\ldots,f_s)\\) contains \\[ \\operatorna{psrc}_j(f_i, f_j) \\] for all \\(1 \\le k \\le d\\). If \\(\\deg(f_i) &gt; 0\\) and \\(\\operatorna{lc}(f_i)\\) is non-constant, then \\(\\operatorname{proj}(f_1,\\ldots,f_i,\\ldots,f_s)\\) contains \\[ \\operatorna{lc}(f_i) \\text[ and } \\operatorname{proj}(f_1,\\ldots,\\operatorna{red}(f_i),\\ldots,f_n). \\] The following theorem follows immediately from the results just proved. Let \\(\\mathbf{F} \\subset \\mathbb{Z}[x_1,\\ldots,x_n]\\) be a family of polynomials and let \\(C&#39;\\) be a connected \\(\\operatorname{proj}(\\mathbf{F})\\)-invariant semialgebraic subset of \\(\\mathbb{R}^{n-1}\\) – an \\((i_1,\\ldots,i_{n-1})\\)-cell. Then there exist continuous definable functions \\[ \\psi_1,\\ldots, psi_\\ell : C&#39; \\to \\mathbb{R} \\] such that for all \\(\\mathbf{x} \\in C&#39;\\), the set \\(\\{ \\psi_i(\\mathbf{x}), \\ldots, \\psi_k(\\mathbf{x}) \\}\\) coincides with the real roots of polynomials in \\(\\mathbf{F}\\), defining the \\((i_1,\\ldots,i_{n-1},0)\\)-cells in the cylinder \\(C&#39; \\times \\mathbb{R}\\) and \\(\\{ -\\infty &lt; t &lt; \\psi_1(\\mathbf{x}), \\ldots, \\psi_i(\\mathbf{x}) &lt; t &lt; \\psi_{i+1}(\\mathbf{x}), \\ldots, \\psi_k(\\mathbf{x}) &lt; t &lt; \\infty \\}\\) are the \\((i_1,\\ldots, i_{n-1},1)\\)-cells in the cylinder \\(C&#39; \\times \\mathbb{R}\\). Suppose we have constructed a CAD of \\(\\mathbb{R}^{k-1}\\) which is sign-invariant with respect to \\(\\operatorname{proj}_{k-1}(\\mathbf{F})\\). Then the preceding theorem can be used to construct a CAD of \\(\\mathbb{R}^{k}\\) which is sign-invariant with respect to \\(\\operatorname{proj}_{k}(\\mathbf{F})\\). More precisely, the CAD is constructed by taking successive projections until the set of projection polynomials is in \\(\\mathbb{Z}[x_1]\\). \\((0)\\)-cells of \\(\\mathbb{R}^1\\) are the roots of these polynomials, while \\((1)\\)-cells are the open intervals in between them. “For \\(1\\le k \\le n-1\\), $lifting” is then performed. I.e., for each cell \\(C&#39;\\) ^k$, the roots of polynomials in the projection set of \\(\\mathbf{F}\\) onto \\(\\mathbb{R}^{k+1}\\) are computed. See, e.g., the appendix of Schwartz and Sharir (1983) for details of how this is done. Since Collins published his CAD algorithm in 1975, many variations of the projection operator have been proposed, most of which aim to minimise the number of polynomials appearing in \\(\\operatorname{proj}_{k-1}(\\mathbf{F})\\), so as to make the algorithm more efficient in practice, while preserving the cylindrical structure. (???) observed that, in dimension \\(2\\), if the set \\(\\mathbf{F} \\subset \\mathbb{Z}[x_1,x_2]\\) of input polynomials is squarefree and pairwise relatively prime, then it is sufficient to include in \\(\\operatorname{proj}(\\mathbf{F})\\) only the leading coefficients, resultants and discriminants of pairs of polynomials in \\(\\mathbf{F}\\). McCallum (1988) then proved that a similar construction is possible in dimension \\(3\\). Later, (???) improved upon his previous work by extending this result to arbitrary dimension, so long as the set of input polynomials is well oriented. Definition 3.4 Let \\(\\mathbf{F} \\subset \\mathbb{Z}[x_1, \\ldots, x_n]\\) be a set of polynomials and denote by \\(\\operatorna{prim}(\\mathbf{F})\\) the set of all primitive parts of \\(\\mathbf{F}\\) \\(\\mathbf{F}\\) is called well-oriented if, when \\(n &gt; 1\\), for each element \\(f \\in \\operatorna{prim}(A)\\), \\(f(\\mathbf{x},y) = 0\\) for all \\(y\\in \\mathbb{R}\\) for only finitely many points \\(\\mathbf{x} \\in \\mathbb{R}^{n-1}\\). \\(\\operatorname{proj}(\\mathbf{F})\\) is well-oriented. Brown (2001) then observed that even more polynomials can be discarded, resulting in the “reduced McCallum projection operator”, which is commonly used in practice. (???) proves that every cell a CAD constructed to be \\(\\mathbf{F}\\)-invariant (where \\(\\mathbf{F} \\subset \\mathbb{Z}[x_1,\\ldots,x_n]\\) is a well-oriented set of polynomials) is an analytic submanifold (??? Theorems 2.2.3 and 2.2.4). An analytic submanifold of \\(\\mathbb{R}^n\\) of dimension \\(k\\) is a non-empty subset \\(S \\subset \\mathbb{R}^n\\) that “looks locally like \\(\\mathbb{R}^s\\)”. Definition 3.5 \\(S \\subset \\mathbb{R}^n\\) is an analytic submanifold if, for every point \\(\\mathbf{x} \\in S\\), there is an analytic coordinate system about \\(\\mathbf{x}\\) with respect to which \\(S\\) is locally the intersection of \\(n-s\\) coordinate hyperplanes. Let \\(\\mathbf{F} \\subset \\mathbb{Z}[x_1,\\ldots,x_n]\\) be a well-oriented set of polynomials. If we want an \\(\\mathbf{F}\\)-invariant CAD such that every cell is an analytic submanifold (smooth subset of \\(\\mathbb{R}^n\\)), it suffices to use McCallum’s projection operator. (???) completed the proof that Lazard’s projection operator is valid and also proved, without the condition on well-orientedness of input polynomials, that every cell of a sign-invariant CAD constructed using Lazard’s projection operator is an analytic submanifold. References "],["4-intro.html", "Chapter 4 Introduction", " Chapter 4 Introduction Based on the work of Basu, Gabrielov and Vorobjov (Basu, Gabrielov, and Vorobjov 2015). Examlpe of another citation, (Collins and Hong 1991). References "],["5-smooth-stratification.html", "Chapter 5 Smooth Stratification", " Chapter 5 Smooth Stratification We now turn our attention to an algorithm for computing a smooth stratification of a semialgebraic set. A smooth stratification is a partition of a semialgebrac set into smooth manifolds. (Whitney 1965) proved that every complex (and real) analytic variety admits a smooth stratification. Later, (Thom 1969) proved that every analytic set admits a smooth stratification and (Lê Loi and others 2010) proved that any set definable in an O-minimal structure also admits a Whitney stratification. In this section, an algorithm due to (Gabrielov and Vorobjov 1995) for computing a basic weak stratification of an elementary semi-pfaffian set, such that each of the strata is “nicely defined” will be presented. Let \\(X \\subset \\mathbb{R}^n\\) be a semianalytic set. \\(X\\) is nonsingular and has dimension \\(k\\) at a point \\(x_0 \\in X\\) if there exist real analytic functions \\[ h_1,\\ldots,h_{n-k} \\] defined in an open set \\(U\\) containing \\(x_0\\) such that \\[ dh_1(x_0) \\ne 0 \\land \\cdots \\land dh_{n-k}(x_0) \\ne 0 \\] and \\[ X \\cap U = \\{ x \\in U \\mid h_1(x) = 0 \\land \\cdots \\land h_{n-k}(x) = 0 \\} \\] Let \\(Y \\subset \\mathbb{R}^n\\) be a semi-pfaffian set. \\(X \\subset Y\\) is called effectively nonsingular (of dimension \\(k\\)) if functions \\(h_1,\\ldots,h_{n-k}\\) belong to the same pfaffian chain as the functions defining \\(Y\\). Definition 5.1 A basic weak stratification of a semi-pfaffian set \\(X \\subset \\mathbb{R}^n\\) is a partition of \\(X\\) into a finite number of non-singular manifolds \\(X_k, 0 \\le k \\le n\\) where each \\(X_k\\) is effectively nonsingularand has codimension \\(k\\). 5.0.1 Description of the algorithm We now present the algorithm from Gabrielov and Vorobjov (1995) as it is applied to semialgebraic sets. Since polynomials are a sub-class of Pfaffian functions, the algorithm can be applied directly to semialgebraic sets. However, in the original form, a bound on the number of partial derivatives is computed. For the semialgebraic case, we simply need to take the degree of polynomials defining the semialgebraic set. Let \\(f \\in \\mathbb{Z}[x_1,\\ldots,x_n]\\) be a polynomial and let \\((m_1,\\ldots,m_n) \\subset \\mathbb{Z}_{\\ge 0}^n\\) be a multi-index of its partial derivative. I.e., we write \\[ \\partial^{(m_1,\\ldots,m_n)} \\] to mean \\[ \\dfrac{\\partial^{m_1} f}{\\partial x_1} \\cdots \\dfrac{\\partial^{m_n} f}{\\partial x_n}. \\] Definition 5.2 We define the partial differential operator \\(\\partial_{\\mathbf{h}, \\mathbf{i}, j} f\\) (where the argument \\(f\\) is a polynomial) as the determinant \\[ \\det\\begin{pmatrix}\\dfrac{\\partial h_{1}}{\\partial x_{i_{1}}} &amp; \\cdots &amp; \\dfrac{\\partial h_{1}}{\\partial x_{i_{k}}} &amp; \\dfrac{\\partial h_{1}}{\\partial x_{j}}\\\\ &amp; \\vdots\\\\ \\dfrac{\\partial h_{k}}{\\partial x_{i_{1}}} &amp; \\cdots &amp; \\dfrac{\\partial h_{k}}{\\partial x_{i_{k}}} &amp; \\dfrac{\\partial h_{k}}{\\partial x_{j}}\\\\ \\dfrac{\\partial f}{\\partial x_{i_{1}}} &amp; \\cdots &amp; \\dfrac{\\partial f}{\\partial x_{i_{k}}} &amp; \\dfrac{\\partial f}{\\partial x_{j}} \\end{pmatrix}. \\] We write \\(\\partial^m_{\\mathbf{h}, \\mathbf{i}, j}\\) to mean the \\(m\\)-th iteration of \\(\\partial_{\\mathbf{h}, \\mathbf{i}, j}\\). We proceed by induction on \\(i_0\\). Base case: \\(i_0 = n\\), return immediately. Recursive case: Initialise \\[X&#39; := X.\\] Consider each multi-index \\(\\mathbf{m} = (i_n,\\ldots,i_{k+1},j} \\subset \\mathbb{Z}_{\\ge 0)^{n-k} \\times \\{1,\\ldots,s\\}\\) in ascending lexicographical order, beginning with \\[ (0,\\ldots,0,1,1). \\] Index \\((i_n,\\ldots,i_1,i_0)\\) has the following property: \\[ M_{i_0} \\preceq (i_n,\\ldots,i_1) \\preceq (0,\\ldots,1), M_{i_0} = \\def(f_i). \\] Let \\((\\mathbf{J}, h_k) \\in \\mathbf{G}\\) such that \\[ \\mathbf{J} = (0, \\ldots, 0, i_{\\ell} - 1, i_{\\ell - 1}, \\ldots, i_{k+1}). \\] Compute \\[ s_k := \\partial_{(h_1,\\ldots,h_k), (i_1,\\ldots,i_k), i_\\all} h_k \\] Define \\[ Y_k := \\{ \\mathbf{x} \\in X&#39; \\mid s_k(\\mathbf{x}) \\ne 0 \\} \\] (Ntoe \\(h_1(\\mathbf{x}) = 0\\) for all \\(\\mathbf{x} \\in Y_k\\).) Define \\[ U_k := \\{ \\mathbf{x} \\in \\mathbb{R}^n \\mid h_k(\\mathbf{x}) = 0, s_k(\\mathbf{x} \\ne 0, g_1(\\mathbf{x}) &gt; 0 , \\ldots, g_l(\\mathbf{}) &gt; 0 \\}, \\] a nonsingular subset of \\(\\mathbb{R}^n\\) having codimension \\(k-1\\) If \\(Y_k\\) is an open subset of \\(U_k\\), then \\(Y_k\\) is nonsingular of codimension \\(k-1\\). Update \\[X_k := X_k \\cup Y_k.\\] Add polynomial \\(s_k\\), i.e., \\[ \\mathbf{G} := \\mathbf{G} \\cup \\{ ((i_\\ell,\\ldots,i_1), s_k) \\} \\] Otherwise, \\(Y_k\\) is not smooth. Call recursively \\[ Stratify((k+1, \\mathbf{G}, (i_\\ell,i_k,\\ldots,i_1,0), (s_k,h_k,\\ldots,h_1,0), \\mathbf{K}) \\] Update \\[ X&#39; := \\{ \\mathbf{x} \\in X&#39; \\mid s_k(\\mathbf{x}) = 0 \\}, \\] a proper (possibly empty) subset of old \\(X&#39;\\). If \\(X&#39; = \\emptyset\\), return. Otherwise, continue with the next index with respect to lexicographical order. Let \\(X \\subset \\mathbb{R}^n := \\{ f_1 = 0 \\land \\cdots \\land f_k = 0 \\land g_1 &gt; 0 \\land \\cdots \\land g_l &gt; 0 \\}\\) be a semialgebraic set. We first apply some pre-processing to the polynomials defining \\(X\\). Let \\[ \\mathbf{G} := ((0,\\ldots,0,1), f_1),\\ldots, ((0,\\ldots,0,s),f_s)). \\] Then the algorithm is called as follows \\[ $\\cal{X} = \\rm{tratify(0, \\mathbf{G}, (0), (0), (g_1,\\ldots,g_t))$. \\] A couple of shortcuts can be taken in the implementation to make the code simpler and more efficient. First, suppose that we are considering index \\[ (0,\\ldots,0,i_\\ell,\\ldots,i_{k+1},i_k,\\ldots,i_1,i_0).\\] Partial differentials with index lexicographically less than \\((i_{k+1},0,\\ldots,0)\\) have been computed on a previous round of induction and were passed in the argument \\(\\mathbf{G}\\). Furthermore, the function \\(h_k\\), having index \\[ (0,\\ldots,0,i_{\\ell -1},\\ldots,i_0) \\] has already been computed, so it can be taken directly from the list \\(\\mathbf{G}\\). In fact, there is a convenient way to find the function with index \\((0,\\ldots,0,i_\\ell - 1, \\ldots,i_1,i_0)\\). Let us first illustrate this with an example. Let \\(M = (1,2,2)\\) and consider the lexicographically ordered list of indices \\[\\begin{matrix} L_1 :=\\ &amp; (0,0,0),&amp;(0,0,1),&amp;(0,0,2),&amp;(0,1,0),&amp;(0,1,1),&amp;(0,1,2),&amp;(1,0,0),&amp;(1,0,1)&amp;\\ldots\\\\ L_2 := \\ &amp; &amp; (0,0,0),&amp;(0,0,1),&amp;(0,0,0),&amp;(0,0,1),&amp;(0,0,2),&amp;(0,0,0),&amp;(0,0,1)&amp;\\ldots.\\\\ \\end{matrix}\\] Observe that for indices \\((0,0,1)\\), \\((0,1,0)\\) and \\((1,0,0)\\) in \\(L_1\\), the corresponding element in \\(L_2\\) is \\((0,0,0)\\) and the corresponding elements for subsequent indices are those in the lexicographical order. I.e., we see that the index of \\(h_k\\) “chases after” the index of \\(s_k\\), resetting each time \\(\\ell\\) is incremented. More precisely, when \\(\\ell = 1\\) and \\(s_1\\) has index \\((0,\\ldots,0,i),i&gt;0\\), $h_1 has index \\((0,\\ldots,0,i-1)\\). I.e., our initial “chase index” is the previous element in the list. When \\(\\ell\\) is incremented, we need to return to the first element in the list, \\((0,\\ldots,0)\\) and proceed lexicographically through the indices until \\(\\ell\\) is incremented again, at which point we return to the beginning of the list. This gives us the property that when \\(h_k\\) has index \\((0,\\ldots,0,i_\\ell,i_{\\ell-1},\\ldots,i_1)\\), \\(h_1\\) will have index \\((0,\\ldots,0,i_\\ell - 1,i_{\\ell - 1},\\ldots,i_1)\\) while only requiring two very basic list operations: get the next element and return to the beginning. In the example, we considered only one polynomial. To extend to multiple polynomials, since each will have a different \\(M\\), we need to keep a separate “chase list” for each one. Since the program has been implemented in QEPCAD, which utilises linked lists, it was important to ensure that appending to the end of the list is as efficient as possible. To avoid \\(O(n)\\) insertion complexity, we keep a pointer to the last-but-one element in the list, i.e., suppose \\(L = (a_1,(\\ldots,(a_{r-1},(a_r,(\\rm{NIL})))\\ldots)\\) then \\(L_{\\rm{append}} = (a_{r-1},(a_r,(\\rm{NIL})))\\). Then, if we wish to append \\(b\\) to the end of \\(L\\), we simply need to set the reductum of \\(L_{\\rm{append}}\\) to \\((a_r,(b,(NIL)))\\). Secondly, observe that only the last row and last column in the \\((k\\times k\\)-matrix for the partial differential operater \\[ \\partial_{\\mathbf{h},\\mathbf{i},j} f = \\det\\begin{pmatrix}\\dfrac{\\partial h_{1}}{\\partial x_{i_{1}}} &amp; \\cdots &amp; \\dfrac{\\partial h_{1}}{\\partial x_{i_{k}}} &amp; \\dfrac{\\partial h_{1}}{\\partial x_{j}}\\\\ &amp; \\vdots\\\\ \\dfrac{\\partial h_{k}}{\\partial x_{i_{1}}} &amp; \\cdots &amp; \\dfrac{\\partial h_{k}}{\\partial x_{i_{k}}} &amp; \\dfrac{\\partial h_{k}}{\\partial x_{j}}\\\\ \\dfrac{\\partial f}{\\partial x_{i_{1}}} &amp; \\cdots &amp; \\dfrac{\\partial f}{\\partial x_{i_{k}}} &amp; \\dfrac{\\partial f}{\\partial x_{j}} \\end{pmatrix}. \\] depend on \\(f\\) and \\(i\\). As a result, we can re-use the \\((k-1\\times k-1)\\)-matrix consisting of the first \\(k-1\\) rows and columns of \\(\\partial_{\\mathbf{h}, \\mathbf{i}, j} f\\). In the implementation, we can receive as an argument, from the previous round of induction, this \\((k-1\\times k-1)\\)-matrix which will be used throughout that round. We still, however, need to compute the determinant for every new \\(s_k\\). We will now present, from (Gabrielov and Vorobjov 1995, Theorem 1), the proof that this algorithm does indeed produce smooth strata and also that it terminates. This algorithm is doubly exponential in the number of variables. For the polynomial case, the complexity is \\[ s^n (d+1)^{2^{O(n)}} \\] where \\(s\\) is the number of polynomials \\(f_1,\\ldots,f_s\\), \\(d\\) is their degree and \\(n\\) is the number of variables. (Gabrielov and Vorobjov 1995, Section 4) References "],["6-quasi-affine-cells.html", "Chapter 6 Quasi-affine cells ", " Chapter 6 Quasi-affine cells "],["6.1-computing-the-smooth-2-dimensional-locus-of-v.html", "6.1 Computing the smooth 2-dimensional locus of \\(V\\)", " 6.1 Computing the smooth 2-dimensional locus of \\(V\\) "],["6.2-ensuring-that-every-cell-is-the-graph-of-a-quasi-affine-map.html", "6.2 Ensuring that every cell is the graph of a quasi-affine map", " 6.2 Ensuring that every cell is the graph of a quasi-affine map "],["7-monotone-cells.html", "Chapter 7 Monotone Cells", " Chapter 7 Monotone Cells Now we have a CAD \\(\\cal D\\) such that each 2-dimensional cell is the graph of a quasi-affine map, let us return to (Basu, Gabrielov, and Vorobjov 2015 Theorem 3.20) and discuss how to obtain monotone cells. Definition 7.1 Let \\(\\cal D\\) be a CAD of \\(\\mathbb{R}^n\\) and suppose that \\(c = \\{ x_1 = c_1,\\dots,x_k = c_k \\}\\) is a \\(0\\)-dimensional section cell in the decomposition induced by \\(\\cal D\\) on \\(\\mathbb{R}^k\\). By (Basu, Gabrielov, and Vorobjov 2015 Remark 3.8), the set of all cells of \\(\\cal D\\) contained in the effing coordinate subspace \\[ \\{ x_1=c_1,\\dots,x_k=c_k \\} \\] forms a cylindrical decomposition of \\(\\mathbb{R}^{n-k}\\). This decomposition will be called the sub-decomposition of \\(\\cal D\\) above \\(c\\), and \\(c\\) the base cell of the sub-decomposition. The construction proceeds by induction on \\(n\\). The base case, \\(n=1\\) is straightforward, since \\((0)\\) and \\((1)\\)-cells are already monotone. When \\(n&gt;1\\), consider each cell \\(C\\) of \\(\\cal D\\) and let \\(C&#39;&#39; := \\operatorname{proj}op{1}(C)\\) If \\(\\dim(C&#39;&#39;) = 0\\), apply the inductive hypothesis to the sub-decomposition of \\(\\cal D\\) above \\(C&#39;&#39;\\). Otherwise, \\(C\\) has index \\(\\{1,i_2,\\dots,i_n\\} \\in \\{0,1\\}^n\\). Let \\(\\alpha\\) be the smallest among \\(\\{2,\\dots,n\\}\\) such that \\(i_\\alpha = 1\\). Then \\(C&#39; := \\operatorname{proj}op{\\alpha}(C)\\) is a 2-dimensional sector cell and \\(C\\) is the graph of a quasi-affine map \\[ \\mathbb{f} = (f_1,\\dots,f_{n-2}) : {\\operatorname{span} \\{x_1,x_\\alpha\\}} \\to {\\operatorname{span} \\{x_2,\\ldots,x_{\\alpha - 1}, x_{\\alpha+1},\\ldots,x_n\\}}. \\] Since \\(\\mathbb{f}\\) is quasi-affine, each component \\(f_j : {\\operatorname{span} \\{x_1,x_\\alpha\\}} \\to {\\operatorname{span} \\{x_j\\}}\\) is quasi-affine, too. Let \\(X \\subset {\\operatorname{span} \\{x_1,x_\\alpha\\}}\\). By (Basu, Gabrielov, and Vorobjov 2015, Lemma 3.18), there exists a refinement of the CAD of \\({\\operatorname{span} \\{x_1,x_\\alpha\\}}\\), obtained by intersecting \\(X\\) with straight lines and half-planes of the kind \\[ \\{x_1 &lt; c\\}, \\{x_1 = c\\}, \\{x_1 &gt; c\\} \\] where \\(c \\in \\mathbb{R}\\), such that \\(X\\) is a union of semi-monotone sets \\(B\\) and \\(f_j\\vert_B\\) is a monotone function. By (Basu, Gabrielov, and Vorobjov 2015 Lemma 3.11), refinements of this kind preserve the cylindrical structure of \\(\\cal D\\). References "],["7.1-two-dimensional-semi-monotone-sectors.html", "7.1 Two-dimensional semi-monotone sectors", " 7.1 Two-dimensional semi-monotone sectors Theorem 7.1 (Basu, Gabrielov, and Vorobjov 2015, Lemma 3.18) Let \\(X \\subset \\mathbb{R}^2\\) be an open, bounded set and \\(f : X \\to \\mathbb{R}\\) be a quasi-affine function. Then there is a cylindrical decomposition of \\(\\mathbb{R}^2\\) compatible with \\(X\\), obtained by intersecting \\(X\\) with straight lines \\[\\{x_1 = c\\}\\] and half-planes \\[\\{x_1 &lt; c\\},\\{x_1 &gt; c\\}\\] such that the restriction \\(f\\vert_B\\) for every cell \\(B \\subset X\\) is a monotone function. 7.1.1 Two-dimensional semi-monotone sets The proof of Theorem 7.1 proceeds in two stages: first, \\(X \\subset {\\operatorname{span} \\{x_1,x_\\alpha\\}}\\) is refined such that each \\(Y \\subset X\\) is a semi-monotone set. Consider the intersection \\(X \\cap \\{x_1 = c\\}\\) for all \\(c\\in \\mathbb{R}\\). This intersection is a finite union of pairwise disjoint intervals. Let \\({\\cal I} (c)\\) be the family of these intervals associated with the point \\(c\\). Define \\[ \\gamma := \\{ (x_1,x_2) \\in \\mathbb{R}^2 \\mid x_2 \\text{ is an endpoint of an interval in } {\\cal I}(x_1) \\}. \\] Lemma 7.1 Let \\(C\\) be a \\((1,0,\\ldots,0,1)\\)-cell and \\(X := {\\operatorname{proj}_{{\\operatorname{span} \\{x_1,x_\\alpha\\}}}} (C)\\). Then \\(X\\) is a cylindrical sector cell in \\(\\mathbb{R}^2\\). The family \\({\\cal I}(C)\\) is either empty or contains a single open interval for all \\(c\\in \\mathbb{R}\\). \\(\\gamma\\) consists of the union of the top and bottom of \\(X\\), each of which (if non-empty) is the graph of a continuous definable function. Proof. Let \\(X&#39; := {\\operatorname{proj}_{\\mathbb{R}^{1}}}(C)\\) and \\(C&#39; := {\\operatorname{proj}_{\\mathbb{R}^{\\alpha-1}}}(C)\\). Observe that \\(X&#39;\\) is a \\((1)\\)-cell and \\(C&#39;\\) is a \\((1,0,\\ldots,0)\\)-cell. By definition \\[ C = \\{ (\\mathbf{x},t) \\mid \\mathbf{x} \\in C&#39;, f(\\mathbf{x}) &lt; t &lt; g(\\mathbf{x})\\} \\] where \\(f,g : \\mathbb{R}^{\\alpha - 1} \\to \\mathbb{R}\\) are continuous definable functions such that \\(f(\\mathbf{x}) &lt; g(\\mathbf{x})\\) for all \\(\\mathbf{x} \\in C&#39;\\). Since \\(C&#39;\\) is a \\((1,0,\\ldots,0)\\)-cell, it can be viewed as the graph of a continuous definable map \\[ \\mathbf{h} = (h_1,\\ldots,h_{\\alpha - 2}) : X&#39; \\to {\\operatorname{span} \\{x_2,\\ldots,x_{\\alpha-1}\\}}. \\] \\(C\\) can therefore be rewritten in terms of only \\(x_1\\) and \\(t\\). \\[ C := \\{ (x_1,\\mathbf{h}(x_1),t) \\mid x_1 \\in X&#39;, f(x_1,\\mathbf{h}(x_1)) &lt; t &lt; g(x_1,\\mathbf{h}(x_1))\\}. \\] Define \\[\\begin{align} \\phi &amp;:\\&gt; C&#39;&#39; \\to \\mathbb{R}&amp; \\psi &amp;:\\&gt; C&#39;&#39; \\to \\mathbb{R}\\\\ \\phi(x_1) &amp;= f(x_1,\\mathbf{h}(x_1)) &amp; \\psi(x_1) &amp;= g(x_1,\\mathbf{h}(x_1)) \\tag{7.1} \\end{align}\\] Observe that \\(\\phi\\) and \\(\\psi\\) are continuous, definable functions. By the definition of \\(f\\) and \\(g\\), we also have \\(\\phi(x_1) &lt; \\psi(x_1)\\) for all \\(x_1\\in X&#39;\\). Thus, we can write \\[\\begin{equation} X = \\{ (x_1,t) \\mid x \\in X&#39;, \\phi(x_1) &lt; t &lt; \\psi(x_1) \\}. \\tag{7.2} \\end{equation}\\] It is clear that \\(X\\) is a cylindrical sector cell. By the definition of sector cell, the bottom of \\(X\\) is the graph of \\(\\phi\\) and the top of \\(X\\) is the graph of \\(\\psi\\). Now consider the family \\[ {\\cal I}(c) := \\{ t \\mid \\phi(c) &lt; t &lt; \\psi(c) \\}. \\] Using Equation (7.2), it is easy to deduce that if \\(c \\in X&#39;\\) then \\({\\cal I}(c)\\) contains a single open interval. On the other hand, if \\(c \\not \\in X&#39;\\), \\({\\cal I}(c)\\) is clearly empty. It follows that \\(\\gamma\\) consists of the points of the top and bottom of \\(X\\), which are the graphs of functions \\(\\psi\\) and \\(\\phi\\) respectively. The refinement is achieved by finding a set of real numbers \\[ (c_1,\\ldots,c_t) \\] such that, for each \\(1 \\le i &lt; t\\), \\[ X \\cap \\{c_i &lt; x_1 &lt; c_i+1\\} \\] is a semi-monotone set. By (Basu, Gabrielov, and Vorobjov 2013, Theorem 1.7), this can be achieved by ensuring that \\[ \\gamma \\cap \\{ c_i &lt; x_1 &lt; c_{i+1}\\} \\] contains only monotone curve intervals. Applying Lemma 7.1 to \\(C\\), we obtain continuous definable functions \\(\\phi,\\psi : X&#39; \\to \\mathbb{R}\\) defining the bottom, \\(X_B\\), and top, \\(X_T\\), of \\(X\\) respectively. Let \\[ (c_1,\\ldots,c_t) \\] be the critical points of functions \\(\\phi\\) and \\(\\psi\\). Then, for all \\(1 \\le i &lt; t\\), \\(\\phi\\) (resp \\(\\psi\\)) is either strictly increasing in, strictly decreasing in, or independent of \\(x_1\\) on the interval \\((c_i, c_{i+1})\\). 7.1.2 Finding the critical points of \\(\\phi\\) and \\(\\psi\\) We now discuss how to find these critical points. Let \\[\\begin{equation} {\\cal A} = ({\\cal A}_1,\\ldots,{\\cal A}_n), \\tag{7.3} \\end{equation}\\] where \\({\\cal A}_i \\subset \\mathbb{Z}[x_1,\\ldots,x_i]\\), be the projection factor set for \\(\\cal D\\). For convenience, we say that \\(g(\\mathbf{x}) = 0\\) for some \\(g \\in A_k\\) and \\(\\mathbf{x} \\in \\mathbb{R}^n\\), such that \\(k &lt; n\\), if \\(g({\\operatorname{proj}_{\\mathbb{R}^{k}}}(\\mathbf{x})) = 0\\). Let \\(C\\) be a \\((1,0,\\ldots,0,1)\\)-cell of the decomposition induced by \\(\\cal D\\) on \\(\\mathbb{R}^{\\alpha}\\) and consider the \\((1,0,\\ldots,0)\\)-cell \\[ C&#39; := {\\operatorname{proj}_{\\mathbb{R}^{\\alpha - 1}}}(C) \\] of the decomposition induced by \\(\\cal D\\) on \\(\\mathbb{R}^{\\alpha - 1}\\). Observe that \\[ {\\operatorname{proj}_{\\mathbb{R}^{1}}}(C) = (a,b) \\subset \\mathbb{R}\\cup \\{-\\infty, \\infty\\} \\] and, since \\(C&#39;\\) is a section cell, there exist polynomials \\[ g_2 \\in {\\cal A_2},\\ldots,g_{\\alpha - 1} \\in {\\cal A_{\\alpha - 1}} \\] such that \\(g_i(\\mathbf{x}) = 0\\) for all \\(1\\le i \\le \\alpha - 1\\) and \\(\\mathbf{x} \\in (C&#39;)\\). Therefore, there exists a one-dimensional algebraic variety \\[ V&#39; := \\left\\{ g_2(\\mathbf{x}) = 0, \\ldots, g_{\\alpha - 1}(\\mathbf{x}) = 0 \\right\\} \\] such that \\(C&#39; \\subset V&#39;\\). Now consider the top of \\(C\\), denoted by \\(C_T\\). By definition, if \\(C\\) is not bounded from above, then \\(C_T\\) does not exist. Otherwise, \\(C_T\\) is the graph of a continuous definable function \\(h : C&#39; \\to \\mathbb{R}\\). In the first case, there is nothing to do, since \\(C_T\\) can be thought of as being independent of \\(x_\\alpha\\). In the second case, \\(C_T\\) can be written as \\[\\begin{equation} \\{ (x_1,\\ldots,x_\\alpha) \\mid a &lt; x_1 &lt; b, g_2(x_1,\\ldots,x_{\\alpha - 1}) = 0, \\ldots, g_{\\alpha - 1}(x_1,\\ldots,x_{\\alpha - 1}) = 0, x_\\alpha = h(x_1,\\ldots,x_{\\alpha - 1}) \\}. \\tag{7.4} \\end{equation}\\] By TODO \\(C_T\\) is \\(C^\\infty\\) smooth, therefore \\(h\\) is a differentiable function everywhere in \\(C&#39;\\). This representation lends itself naturally to the problem of Lagrange multipliers. Proposition 7.1 Let \\(f : \\mathbb{R}^n \\to \\mathbb{R}\\) and \\(g_1,\\ldots,g_k : \\mathbb{R}^n \\to \\mathbb{R}\\) be continuous functions with continuous first partial derivatives. Local maxima and minima of \\(f\\), subject to the constraints \\(g_1=0,\\ldots,g_k=0\\) can be found by computing the critical points of the function \\[ \\mathcal{L}(\\mathbf{x}, \\lambda_1,\\ldots,\\lambda_k) = f(\\mathbf{x}) - \\lambda_1 g_1(\\mathbf{x}) - \\cdots - \\lambda_k g_k(\\mathbf{x}), \\] where \\(\\mathbf{x} \\in \\mathbb{R}^n\\) and \\((\\lambda_1,\\ldots,\\lambda_k) \\in \\mathbb{R}^k\\) are new variables. Critical points can be found by solving the system of equations \\[\\begin{equation} \\dfrac{\\partial f}{\\partial x_i} - \\lambda_1 \\dfrac{\\partial g_1}{\\partial x_i} - \\cdots - \\lambda_k \\dfrac{\\partial g_k}{\\partial x_i}= 0, \\tag{7.5} \\end{equation}\\] where \\(1\\le i \\le n-1\\), for \\(\\lambda_1,\\ldots,\\lambda_k\\). Remark. Using variables \\((x_1,\\ldots,x_{\\alpha-1})\\), constraints \\(g_2,\\ldots,g_{\\alpha - 1}\\) and function \\(h\\) from Equation (7.4), the system from Equation (7.5) can be written in matrix form as follows. \\[ \\begin{pmatrix}\\dfrac{\\partial g_{2}}{\\partial x_{1}} &amp; \\cdots &amp; \\dfrac{\\partial g_{\\alpha-1}}{\\partial x_{1}}\\\\ \\vdots &amp; &amp; \\vdots\\\\ \\dfrac{\\partial g_{2}}{\\partial x_{\\alpha-1}} &amp; \\cdots &amp; \\dfrac{\\partial g_{\\alpha-1}}{\\partial x_{\\alpha-1}} \\end{pmatrix}\\begin{pmatrix}\\lambda_{1}\\\\ \\vdots\\\\ \\lambda_{\\alpha-2} \\end{pmatrix}=\\begin{pmatrix}\\dfrac{\\partial h}{\\partial x_{1}}\\\\ \\vdots\\\\ \\dfrac{\\partial h}{\\partial x_{\\alpha-1}} \\end{pmatrix} \\] It is clear that, if a solution exists, then the last column \\(\\left(\\tfrac{\\partial h}{\\partial x_{1}},\\ldots, \\tfrac{\\partial h}{\\partial x_{\\alpha-1}}\\right)^T\\) will be a linear combination of the first \\(\\alpha - 1\\) columns (in \\(g_2,\\ldots,g_{\\alpha - 1}\\)). Hence, optimal values for \\((x_1,\\ldots,x_{\\alpha-1})\\) exist and satisfy \\[\\begin{equation} \\det\\begin{pmatrix}\\dfrac{\\partial g_{2}}{\\partial x_{1}} &amp; \\cdots &amp; \\dfrac{\\partial g_{\\alpha-1}}{\\partial x_{1}} &amp; \\dfrac{\\partial h}{\\partial x_{1}}\\\\ \\vdots &amp; &amp; &amp; \\vdots\\\\ \\dfrac{\\partial g_{2}}{\\partial x_{\\alpha-1}} &amp; \\cdots &amp; \\dfrac{\\partial g_{\\alpha-1}}{\\partial x_{\\alpha-1}} &amp; \\dfrac{\\partial h}{\\partial x_{\\alpha-1}} \\end{pmatrix}=0. \\tag{7.6} \\end{equation}\\] Equation (7.6) gives a direct formula for formula to solve Equation (7.5) for \\(x_1,\\ldots,x_{\\alpha - 1}\\). Refinement points \\((c_1,\\ldots,c_t)\\) are the \\(x_1\\)-coordinates of these solutions. Since \\(C_T\\) is a section cell, there exists a polynomial \\(g_\\alpha \\in {\\cal A}_\\alpha\\) such that \\[ C_T := \\{ \\mathbf{x} \\in \\mathbb{R}^\\alpha \\mid {\\operatorname{proj}_{\\mathbb{R}^{\\alpha - 1}}}(\\mathbf{x}) \\in C&#39;, g_\\alpha(\\mathbf{x}) = 0 \\}. \\] Thus, there exists an algebraic variety \\[\\begin{equation} V := \\left\\{ g_2(\\mathbf{x}) = 0, \\ldots, g_{\\alpha-1}(\\mathbf{x}) = 0 g_\\alpha(\\mathbf{x}) = 0 \\right\\} \\tag{7.7} \\end{equation}\\] such that \\(C_T \\subset V\\), where \\(g_2,\\ldots,g_{\\alpha - 1}\\) are the same polynomials appearing in Equation (7.4). Note that \\(g_\\alpha \\in \\mathbb{Z}[x_1,\\ldots,x_\\alpha]\\), while \\(h\\) from Equation (7.6) is expected to be a continuous differentiable function from \\(\\mathbb{R}^{\\alpha - 1} \\to \\mathbb{R}\\). We need to compute derivatives of the implicit \\(g_\\alpha\\). I.e., \\[\\begin{equation} \\dfrac{d x_\\alpha}{d x_i} = \\dfrac{\\partial g_\\alpha / \\partial x_i}{\\partial g_\\alpha / \\partial x_\\alpha} \\tag{7.8} \\end{equation}\\] for \\(1\\le i \\le \\alpha - 1\\). Let \\(J_T\\) be the determinant of the matrix of partial derivatives from Equation (7.6) with each \\(\\partial h / \\partial x_i, 1 \\le i \\le \\alpha - 1\\) replaced with \\(d x_\\alpha / d x_i\\) from Equation (7.8). Observe that the denominator of \\(\\partial h / \\partial x_i\\), for all \\(1 \\le i \\le \\alpha - 1\\), is equal to \\[d_T := \\partial g_\\alpha / \\partial x_\\alpha,\\] so the last column of the matrix can be written as \\[ \\dfrac{1}{d_T} \\left( \\partial g_{\\alpha} / x_1 , \\ldots , \\partial g_{\\alpha} / x_{\\alpha - 1}\\right)^T. \\] Thus, the determinant \\[ J_T = \\frac{1}{d_T} J&#39;_T, \\] where \\(J&#39;_T\\) is the matrix from Equation (7.6) with the \\(\\partial h / \\partial x_i\\) replaced with \\(\\partial g_\\alpha / \\partial x_i\\) for \\(1\\le i \\le \\alpha - 1\\). I.e., \\[\\begin{equation} \\det\\begin{pmatrix}\\dfrac{\\partial g_{2}}{\\partial x_{1}} &amp; \\cdots &amp; \\dfrac{\\partial g_{\\alpha-1}}{\\partial x_{1}} &amp; \\dfrac{\\partial g_\\alpha}{\\partial x_{1}}\\\\ \\vdots &amp; &amp; &amp; \\vdots\\\\ \\dfrac{\\partial g_{2}}{\\partial x_{\\alpha-1}} &amp; \\cdots &amp; \\dfrac{\\partial g_{\\alpha-1}}{\\partial x_{\\alpha-1}} &amp; \\dfrac{\\partial g_\\alpha}{\\partial x_{\\alpha-1}} \\end{pmatrix}=0. \\tag{7.9} \\end{equation}\\] Observe that \\(J_T\\) is a rational function: a fraction in which the numerator and denominator are both polynomials. \\(\\mathbf{x} \\in \\mathbb{R}^{\\alpha - 1}\\) is a solution of this rational function if and anly if \\(J&#39;_T(\\mathbf{x}) = 0\\) and \\(d_T(\\mathbf{x}) \\ne 0\\). Thus, solutions of the system \\[ \\{ J&#39;_T = 0, d_T \\ne 0 \\} \\] should be found. Observe that this is a semialgebraic set, since $ { d_T() } ^{- 1 } { d_T() = 0 } $. Note that, when \\(\\deg(d_T) = 0\\), \\(d_T\\) is a constant and therefore has no solutions. Thus, the condition \\(d_T = 0\\) can be dropped. Repeating this process to obtain \\(J&#39;_B\\) and \\(d_B\\), if sector cell \\(C\\) is bounded from below, we have a set of polynomial equations \\[\\begin{equation} \\{ g_2,\\ldots,g_{\\alpha-1}, J&#39;_B, J&#39;_T \\}, \\tag{7.10} \\end{equation}\\] and inequalities \\[\\begin{equation} \\{ s_1 g_{1,1} &gt; 0, \\ldots, s_\\ell g_{1,\\ell} &gt; 0, d_B \\ne 0, d_T \\ne 0 \\} \\tag{7.11} \\end{equation}\\] where \\(\\{ g_{1,1},\\ldots,g_{1,\\ell} \\} \\subset \\mathbb{Z}[x_1]\\) are polynomials from \\({\\cal A}_1\\) and \\(s_1,\\ldots,s_\\ell \\in \\{-1,1\\}\\) such that \\[ x \\in X&#39; \\leftrightarrow s_1 g_{1,1}(x) &gt; 0 \\land \\ldots \\land s_\\ell g_{1,\\ell}(x) &gt; 0. \\] We can easily find pairs \\((s_j, g_{1,j}) \\in \\{-1,1\\} \\times {\\cal A}_1\\) by considering the sign of the sample point \\(c\\) of \\(X&#39;\\) on each polynomial \\(g_{1,j} \\in {\\cal A}_1\\). If \\(g_{1,j} &gt; 0\\), then \\(s_j = 1\\). If \\(g_{1.j}(c) &lt; 0\\), then \\(s_j = -1\\). The final case, \\(g_{1,j}(c) = 0\\), is impossible since an irreducible univariate polynomial cannot be zero over an interval. We want to find \\(x_1\\)-coordinates of the roots of polynomials from Equation (7.10) subject to the constraints from Equation (7.11). CAD can, of course, be used to do this, since we are really solving the quantifier elimination problem \\[ \\exists x_2,\\ldots,x_{\\alpha - 1},x_\\alpha P(x_1,\\ldots,x_\\alpha) \\] where \\[\\begin{align} P(x_1,\\ldots,x_\\alpha) = &amp; s_1 g_{1,1}(x_1) &gt; 0 \\land \\ldots \\land s_\\ell g_{1,\\ell}(x_1) &gt; 0 \\tag{7.12} \\\\ \\land &amp; g_2(x_1,x_2) = 0 \\land \\ldots \\land g_{\\alpha - 1}(x_1,\\ldots,x_{\\alpha - 1} = 0 \\tag{7.13} \\\\ \\land &amp; d_B(x_1,\\ldots,x_\\alpha) \\ne 0 land d_T(x_1,\\ldots,x_\\alpha) \\ne 0 \\tag{7.14} \\\\ \\land &amp; ( J&#39;_B(x_1,\\ldots,x_{\\alpha - 1} = 0 \\lor J&#39;_T(x_1,\\ldots,x_{\\alpha - 1}) = 0 ). \\tag{7.15} \\\\ \\end{align}\\] Computing the projection onto \\(\\mathbb{R}^1\\) of polynomials \\(\\{g_2,\\ldots,g_{\\alpha - 1} J&#39;_B, J&#39;_T \\}\\) from Equations (7.13) and (7.15), a system \\[ \\cal{F} := \\{ f_1=0 ,\\ldots,f_r=0 \\} \\subset \\mathbb{Z}[x_1] \\] is obtained, whose real roots include the refinement points \\((c_1,\\ldots,c_t)\\). Let \\({\\cal E} \\subset \\mathbb{Z}[x_1]\\) be the set of polynomials obtained by computing the projection onto \\(\\mathbb{R}^1\\) of \\(\\{ d_B, d_T \\}\\) (from Equation (7.14)) and \\[{\\cal G} := \\{ s_1 g_{1,1}, \\ldots, s_\\ell g_{1,\\ell} \\} \\] from Equation (7.12). \\((c_1,\\ldots,c_t\\) can be found by computing the real roots of \\(\\cal F\\) subject to the inequalities \\(\\cal G\\), then discarding those such that a polynomial in \\(\\cal E\\) is zero. In the implementation IPFSFB is used, to compute a “finest square-free basis” of polynomials in \\(\\cal F\\). this was just copying from Brown’s CONSTRUCT function. it returns a list of real roots in the form \\([(M,J),...]\\) where \\(M\\) is the minimal polynomial and \\(J\\) the isolating interval. It also computes multiplicities, which we don’t need. in fact, why do we even need a squarefree basis at all. should find out which is the most efficient algorithm from saclib, of squarefree basis or the real root finding algorithms. maybe do some discussion on this. It is clear that \\((c_1,\\ldots,c_t)\\) lie in an open interval \\(X = (a,b) \\subset \\mathbb{R}\\cup \\{ -\\infty, \\infty \\}\\). Thus, rather than using strict inequalities from Equation (7.12), we could find the roots of \\(\\cal F\\) in the interval \\((a,b)\\). Each real root will be represented by a pair \\[ c_i := (m_1,J_1) \\] where \\(c_i\\) is the unique root of the polynomial \\(m_i \\in \\mathbb{Z}[x_1]\\) in the (left-open right-closed) isolating interval \\(J_i\\). Note that \\(\\cal B\\) contains only algebraic numbers and roots will appear in ascending order. 7.1.3 Working with sub-decompositions above a 0-cell Note that we are working in a sub-decomposition \\(\\cal D\\) of \\(\\mathbb{R}^{k+n}\\) above a \\(0\\)-cell \\(\\mathbf{c}\\) of \\(\\mathbb{R}^k\\) (\\(k \\ge 0\\)). Therefore the polynomials appearing in Equation (7.7) are actually in \\(\\mathbb{Z}[y_1,\\ldots,y_k][x_1,\\ldots,x_n]\\). From a polynomial \\(f \\in \\mathbb{Z}[y_1,\\ldots,y_k][x_1,\\ldots,x_n]\\), a polynomial \\(g := f(\\mathbf{c}) \\in \\mathbb{A}[x_1,\\ldots,x_n]\\) can be obtained by evaluating \\(f\\) at \\(\\mathbf{c}\\). Evaluated polynomials \\(g\\) define the sub-cad of \\(\\mathbb{R}^n\\) above \\(\\mathbf{c}\\) because \\(\\mathbf{c}\\) is a \\(0\\)-cell. Note that, since \\(\\mathbf{c}\\) is an algebraic number, \\(g\\) has algebraic coefficients. Since roots of \\(g\\) are algebraic numbers, there exists a polynomial \\(h \\in \\mathbb{Z}[x_1,\\ldots,x_n]\\) such that, \\(g(\\mathbf{x}) = 0\\) if and only if \\(h(\\mathbf{x}) = 0\\) for all \\(\\mathbf{x} \\in \\mathbb{R}^n\\). A method for obtaining the polynomial \\(h\\) with integer coefficients is now described. If \\(f\\) is independent of all \\(y_1,\\ldots,y_k\\), there is nothing to do, just set \\(h := f\\). Otherwise, \\(f\\) depends on at least one of \\(y_1,\\ldots,y_k\\). If \\(\\mathbf{c}\\) is rational, then \\(g = f(\\mathbf{c})\\) has coefficients in \\(\\mathbb{Q}\\). There exists a non-zero \\(a \\in \\mathbb{Z}\\) such that \\(h := a g\\) has integer coefficients and the same roots as \\(g\\). Otherwise, \\(\\mathbf{c}\\) is not rational. Then \\(f(\\mathbf{c})\\) has coefficients in \\(\\mathbb{A}\\). There exists an algorithm, which takes \\(g\\) as input and returns a polynoial \\(h \\in \\mathbb{Z}[x_1,\\ldots,x_n]\\) such that \\(g(\\mathbf{x}) = 0\\) if and only if \\(h(\\mathbf{x}) = 0\\) for all \\(\\mathbf{x} \\in \\mathbb{R}^n\\). Remark. Let \\(f \\in \\mathbb{Q}[x_1,\\ldots,x_n]\\) be a polynomial such that \\[ f(x_1,\\ldots,x_n) = \\dfrac{a_1}{b_1} m_1 + \\cdots + \\dfrac{a_k}{b_k} m_k \\] where \\(m_i = x_1^{d_{i,1}} \\cdots x_n^{d_{i,n}}\\) for \\(1 \\le i \\le k\\) is a monomial in \\(x_1,\\ldots,x_n\\). Let \\(M := \\operatorname{lcm}(b_1, \\ldots, b_k)\\) be the least common multiple of denominators and construct \\[ g(x_1,\\ldots,x_n) = M f(x_1,\\ldots,x_n) = \\dfrac{M a_1}{b_1} m_1 + \\cdots + \\dfrac{M a_k}{b_k} m_k. \\] Each coefficient in \\(g\\) will be an integer number since \\(M\\) is divisible by all \\(b_1,\\ldots,b_k\\) and polynomials \\(f\\) and \\(g\\) have the same roots. Definition 7.2 Let \\(K\\) be a field and \\(L\\) a finite (algebraic) extension of \\(K\\). The field \\(L\\) can be thought of as a finite dimensional vector space over \\(K\\). Consider \\(f\\) and \\(m\\) as polynomials in \\(\\mathbb{Q}[x_1,\\ldots,x_n,x_\\alpha]\\). compute the resultant of \\(f\\) and \\(m\\) to obtain a polynomial in \\(\\mathbb{Q}[x_1,\\ldots,x_n]\\). somehow this gives us the norm of an algebraic polynomial. Remark. Let \\(f \\in \\mathbb{A}[x_1,\\ldots,x_n]\\) be a polynomial such that \\[ f(x_1,\\ldots,x_n) = a_1 m_1 + \\cdots + a_k m_k \\] where \\(m_i = x_1^{d_{i,1}} \\cdots x_n^{d_{i,n}}\\) is a monomial in \\(x_1,\\ldots,x_n\\) and \\(a_i\\) is an element of \\(\\mathbb{Q}(\\alpha)\\) for \\(1 \\le i \\le k\\). Let \\(m \\in \\mathbb{Z}[\\alpha]\\) be the minimal polynomial for \\(\\mathbb{Q}(\\alpha)\\). \\(f\\) can be written as a polynomial in \\(\\mathbb{Q}[x_1,\\ldots,x_n,\\alpha]\\) and \\(m\\) can be viewed as a polynomial in \\(\\mathbb{Z}[x_1,\\ldots,x_n,\\alpha]\\) which is independent of all \\(x_1,\\ldots,x_n\\). Compute \\[ g := \\operatorname{Res}_\\alpha (f,m) \\] to obtain a polynomial in \\(\\mathbb{Q}[x_1,\\ldots,x_n]\\). The property that \\(f(\\mathbf{x}) = 0\\) if and only if \\(g(\\mathbf{x}) = 0\\) follows from the following property of resultants: Let \\(I = \\langle f, m \\rangle\\) be the ideal generated by polynomials \\(f, m \\in K[x_1,\\ldots,x_n][\\alpha]\\), where \\(K\\) is an algebraically closed field. If at least one of \\(f\\) and \\(m\\) is monic, then \\[ \\operatorname{Res}_\\alpha (f,m) \\in I \\cap R. \\] It follows that \\(\\mathbf{x} \\in K^n\\) is a common zero of the elements of \\(I \\cap R\\) if and only if it is a zero of \\(\\operatorname{Res}_\\alpha(f,m)\\). TODO this property came from the wiki page on resultants. does it need proving? References "],["7.2-two-dimensional-monotone-sections.html", "7.2 Two-dimensional monotone sections", " 7.2 Two-dimensional monotone sections Recall \\(X := {\\operatorname{proj}_{{\\operatorname{span} \\{x_1,x_\\alpha\\}}}}(C)\\) and let \\((c_1,\\ldots,c_r)\\) be the refinement points computed in the previous section such that \\[ Y := \\{ c_i &lt; x_1 &lt; c_{x+1}\\} \\cap X, \\] for some \\(1 \\le i \\le r\\), is a two-dimensional semi-monotone set. Let us return to (Basu, Gabrielov, and Vorobjov 2015, Theorem 3.18) to further refine \\(Y\\) such that every two-dimensional section cell is a monotone cell. Let \\(f_j : Y \\to {\\operatorname{span} \\{x_j\\}}\\) be a component of the quasi-affine map \\(\\mathbf{f} : X \\to \\mathbb{R}\\). Since \\(\\mathbf{f}\\) is quasi-affine, each component of \\(\\mathbf{f}\\) is quasi-affine and the restriction of component \\(f_j\\) to \\(Y\\) is quasi-affine since \\(Y \\subset X\\). Hence, \\(f_j\\) is either strictly increasing in, strictly decreasing in, or independent of each variable \\(x_1, x_\\alpha\\). In addition, the restriction \\(f\\vert_{Y \\cap \\{x_\\alpha = c\\}}\\) for any \\(c \\in \\mathbb{R}\\) is either strictly increasing in, strictly decreasing in, or independent of \\(x_\\alpha\\). We will compute a refinement of \\(Y\\) such that \\(f_j\\vert_Y\\) is monotone, each \\(B \\subset Y\\) in the refinement. As before, only refinements of the kind \\[ \\{ x_1 &lt; c \\}, \\{ x_1 = c \\}, \\{ x_1 &gt; c \\}, \\] \\(c \\in \\mathbb{R}\\), which preserves both the cylindrical structure and existing monotone cells will be performed. 7.2.1 Case 1: \\(2 \\le j \\le \\alpha - 1\\) Lemma 7.2 Let \\(Y \\subset \\mathbb{R}^n\\) be the graph of a quasi-affine map \\[ \\mathbf{f} : (a,b) \\to \\mathbb{R}^{n-1} \\] such that \\((a,b) \\subset \\mathbb{R}\\). Then \\(Y\\) is a monotone cell. Proof. It is clear that \\[ \\dim(Y) = 1. \\] Hence, we need to show that \\(Y\\) is either strictly increasing in, strictly decreasing in, or independent of \\(x_i\\) for all \\(1\\le i \\le n\\). Consider the projection map \\({\\operatorname{proj}_{{\\operatorname{span} \\{x_i\\}}}} : \\mathbb{R}^n \\to {\\operatorname{span} \\{x_i\\}}\\). Suppose that the restriction \\[ {\\operatorname{proj}_{{\\operatorname{span} \\{x_i\\}}}}\\vert_Y \\] is injective, Then it is clear that the image \\({\\operatorname{proj}_{{\\operatorname{span} \\{x_i\\}}}}(Y)\\) is \\(1\\)-dimensional, since \\(Y\\) itself is \\(1\\)-dimensional. On the other hand, suppose that the image \\[ {\\operatorname{proj}_{{\\operatorname{span} \\{x_i\\}}}}(Y) \\] is one-dimensional, then it is clear that \\({\\operatorname{proj}_{{\\operatorname{span} \\{x_i\\}}}}\\vert_Y\\) is injective if \\(\\mathbf{f}\\) is either strictly increasing in, strictly decreasing in, or independent of \\(x_i\\). It follows that \\(\\mathbf{f}\\) is a monotone map, therefore its graph, \\(Y\\), is a monotone cell. Suppose that \\(2 \\le j \\le \\alpha - 1\\). Since \\[ {\\operatorname{proj}_{{\\operatorname{span} \\{x_j,x_\\alpha\\}}}}(C) \\] is one-dimensional, connected and the graph of a quasi-affine map, it follows from Lemma 7.2 that \\({\\operatorname{proj}_{{\\operatorname{span} \\{x_j,x_\\alpha\\}}}}(C)\\) is a monotone cell and \\(f_j\\vert_Y\\) is already a monotone function. No refinement is needed. 7.2.2 Case 2: \\(\\alpha + 1 \\le j \\le n\\) Now suppose that \\(\\alpha + 1 \\le j \\le n\\). By (Basu, Gabrielov, and Vorobjov 2013, Theorem 3), if functions \\[\\inf_{x_\\alpha} f_j : {\\operatorname{span} \\{x_1\\}} \\to {\\operatorname{span} \\{x_j\\}} \\text{ and } \\sup_{x_\\alpha} f_j : {\\operatorname{span} \\{x_1\\}} \\to {\\operatorname{span} \\{x_j\\}}\\] are monotone, then \\(f_j\\) itself is monotone. Hence, we need to find refinement points \\[ \\{ b_1,\\ldots,b_r \\} \\subset (c_i,c_{i+1}) \\] such that, for each \\(1\\le \\ell &lt; r\\), the restrictions of both \\(\\inf_{x_\\alpha} f_j\\) and \\(\\sup_{x_\\alpha} f_j\\) to \\(B := \\{ b_\\ell &lt; x_1 &lt; b_{\\ell + 1} \\}\\) are monotone. Consider \\[ Z := {\\operatorname{proj}_{{\\operatorname{span} \\{x_1,x_j\\}}}}(C). \\] If \\(\\dim(Z) &lt; 2\\), then it is clear that \\(\\dim(Z) = 1\\), because \\[ Y&#39; := {\\operatorname{proj}_{\\mathbb{R}^{1}}}(C) \\] is one-dimensional. It follows that \\(\\inf_{x_\\alpha} f_j\\) and \\(\\sup_{x_\\alpha} f_j\\) coincide. Since \\(Z\\) is one-dimensional, connected and the graph of a quasi-affine map, Lemma 7.2 implies that \\(f_j\\) is already monotone and no refinement is needed. On the other hand, if \\(\\dim(Z) = 2\\), since \\(\\mathbf{f}\\) is quasi-affine, \\({\\operatorname{proj}_{{\\operatorname{span} \\{x_1,x_j\\}}}}\\vert_C\\) is injective. Let \\(Z_T\\) be the graph of \\(\\sup_{x_\\alpha} f_j\\). Despite the notation, \\(Z_T\\) is not necesarily the top of \\(Z\\). In particular, \\(Z_T\\) may have non-empty intersection with \\(Z\\). Since semialgebraic sets are closed under intersection and projection, there exist points \\[\\{b_1,\\ldots,b_k\\} \\subset (c_i,c_{i+1}) \\] such that for all \\(1 \\le i &lt; k\\) \\[ Z^{b_i,b_{i+1}}_T := Z_T \\cap \\{ b_i &lt; x_1 &lt; b_{i+1} \\} \\] is either a subset of \\(Z\\) or is disjoint from \\(Z\\). First suppose that \\(Z^{b_i,b_{i+1}}_T \\subset Z\\) for some \\(1 \\le i &lt; k\\). In this case, \\(Z\\) is not bounded from above, so \\(\\sup_{x_\\alpha} f_j \\vert_{\\{ b_i &lt; x_1 &lt; b_{i+1} \\}}\\) is independent of \\(x_1\\) and is therefore already monotone. On the other hand, suppose that \\(Z^{b_i,b_{i+1}}_T \\cap Z = \\emptyset\\). In this case, \\(Z^{b_i,b_{i+1}}_T \\subset {\\operatorname{proj}_{{\\operatorname{span} \\{x_1,x_j\\}}}}(C_T)\\). If there exists a point \\(b \\in (b_i,b_{i+1})\\) such that \\({\\operatorname{proj}_{{\\operatorname{span} \\{x_1,x_j\\}}}}(C_T) \\cap \\{x_1 = b\\} \\cap Z \\neq \\emptyset\\), then it is clear that \\(C_T \\cap \\{ b_i &lt; x_1 &lt; b_{i+1} \\}\\) is not the graph of a continuous function. I.e., \\({\\operatorname{proj}_{{\\operatorname{span} \\{x_1,x_\\alpha,x_j\\}}}}(C_T)\\) contains an open interval above \\((b,y) \\in Y_T\\). Since \\(\\dim(C) = 2\\), all blow-up points \\((b,y)\\) have dimension \\(0\\) and therefore there is a finite number of them. Repeating this process for \\(\\alpha + 1 \\le j \\le n\\), it follows that there exist points \\[\\{ b_{i,1}, \\ldots, b_{i,k_i} \\} \\subset (b_i, b_{i+1}) \\] such that, for all \\(1 \\le j &lt; k_i\\), \\(C_T \\cap \\{ b_{i,j} &lt; x_1 &lt; b_{i,j+1} \\}\\) is the grah of a continuous map. In particular, \\(C_T \\cap \\{ b_{i,j} &lt; x_i &lt; b_{i,j+1} \\}\\) is the graph of \\(\\mathbf{f}\\vert_{Y_T \\cap \\{ b_{i,j} &lt; x_1 &lt; b_{i,j+1} \\}}\\). Apply the same argument to \\(\\inf_{x_\\alpha} f_j\\) (for \\(C_B\\)) so that, \\(C_T\\) and \\(C_B\\), if non-empty, are split into one-dimensional countinuous curves which are graphs of continuous functions, and the intervals above \\(0\\)-dimensional blow-up points. Once this property has been satisfied, we are left with a similar construction of optimisation with constraints as in Scetion 7.1.2. 7.2.3 Critical points of the top and bottom of \\(C\\) We now discuss how to perform this refinement on the CAD structure. Let us assume that \\(C_T\\ne \\emptyset\\). We must construct subsets \\(W \\subset Y\\) such that \\(f_j\\vert_{W_T}\\) is a smooth, continuous functions. Let \\[ {\\cal A} = ({\\cal A}_1, \\ldots, {\\cal A}_n) \\] be the projection factor set as defined in Equation (7.3) and \\[ C&#39; := {\\operatorname{proj}_{\\mathbb{R}^{j-1}}}(C), C^j := {\\operatorname{proj}_{\\mathbb{R}^{j}}}(C), \\] Begin with \\(j := \\alpha+1\\) so that \\(C&#39;\\) is a cylindrical sector cell and there exists an algebraic variety \\(V\\) containing polynomials \\(g_2,\\ldots,g_{j-1}\\) with each \\(g_i \\in {\\cal A}_i, 2 \\le i \\le j-1\\), defined in Equation (7.4), such that \\(C&#39;_T\\subset V\\). By definition \\[ C^j_T = {\\operatorname{cl} \\left( C^j \\right)} \\cap (C&#39;_T \\times \\mathbb{R}) \\] and there exists a polynomial \\(g_j \\in {\\cal A}_j\\) such that \\(g_j(\\mathbf{x}) = 0\\) for all \\(\\mathbf{x} \\in C^j_T\\). Since \\(C^j_T\\) is either empty or the graph of a continuous function everywhere except, possibly, for a finite number of blow-up points, we need to find \\(x_1\\)-coordinates of points in \\(C&#39;_T\\) such that \\(g_j\\) vanishes over an open interval. Since \\(C^j_T\\) is one-dimensional, one way to achieve this is by computing a smooth stratification of \\(C^j_T\\). If the projection of a one-dimensional stratum onto \\(x_1\\) is a \\(0\\)-dimensional point \\(b \\in \\mathbb{R}\\), then \\(b\\) is the \\(x_1\\)-coordinate of a blow-up point. Alternatively, since the refinement points form a \\(0\\)-dimensional semialgebraic subset of \\(\\mathbb{R}\\), this set can be represented as a first-order Boolean formula \\[ \\exists x_2,\\ldots,x_{j-1} \\exists_\\infty x_j ((x_1,\\ldots,x_{j-1}) \\in C&#39;_T, g_j(x_1,\\ldots,g_j) = 0) \\] where \\(\\exists_\\infty x\\) is a special quantifier defined in QEPCAD meaning “there exist infinitely many values of \\(x\\)”. Using \\(\\exists_\\infty\\), som of the costly computations with algebraic numbers can be avoided, thereby improving efficiency in practice. TODO refer to qepcad user documentation. Theoretically speaking, (Basu, Pollack, and Roy 2006, Algorithm 14.21) provides a singly exponential upper bound for quantifier elimination. TODO what is the bound? Eliminating the \\(j-1\\) quantifiers, we obtain the desired points \\((b_{i,1},\\ldots,b_{i,k_i})\\), where each \\(b_{i,j}\\) is the \\(x_1\\)-coordinate of a blow-up point of \\(g_j\\). Now we can assume that \\(C^j_T\\cap \\{ b_{i,j} &lt; x_1 &lt; b_{i,j+1}\\}\\) is the graph of a continuous function. More precisely, the implicit function \\(g_j\\) can be considered as a function from \\(C&#39;_T \\cap \\{ b_{i,j} &lt; x_1 &lt; b_{i,j+1}\\}\\) to \\(\\mathbb{R}\\). We have a very similar construction as in Section 7.1.2. That is, polynomials \\(g_2,\\ldots,g_{j-1}\\) will provide the constraints in the first \\(j-2\\) columns of the matrix in Equation (7.6), while \\(\\partial h / \\partial x_i, 1 \\le i \\le j - 1\\) in the last column should be replaced with \\(\\partial g_j / \\partial x_i\\) Denote this polynomial by \\(J_T\\), and repeat with \\(C^j_B\\) if appropriate. Inequalities \\(s_1 g_{1,1} &gt; 0, \\ldots, s_1 g_{1,\\ell} &gt; 0\\) (from Equation (7.12)), \\(d_T \\ne 0\\) and \\(d_B\\) (from Equation (7.14)) are obtained and solved for \\(x_1\\) in a very similar way as in Section 7.1.2. We obtain a set of refinement points \\[ \\{ b_{j,1}, \\ldots, b_{j,r_j} \\} \\subset (c_i,c_{i+1}) \\] such that each of \\(C^j_T\\) and \\(C^j_B\\) is either empty or the graph of a continuous, monotone function. The process is completed by induction in \\(j\\). Suppose that the refinement has been performed for \\(\\alpha + 1 \\le j\\). If \\(j = n\\) we are done, and \\(C\\) is now monotone. Otherwise, let \\(j := j+1\\). By the induction hypothesis, we know that \\(C^{j-1}_T \\cap \\{b_{j-1,i} &lt; x_1 &lt; b_{j-1,i+1}\\}, 1 \\le i &lt; r_{j-1}\\) is either empty or the graph of a continuous function. If \\(C^{j-1}_T = \\emptyset\\), there is nothing to do and the process will terminate, since \\(C^j_T\\) is empty. Otherwise, take \\(g_{j-1} \\in {\\cal A}_{j-1}\\) used in the induction hypothesis and find \\(g_j \\in {\\cal A}_j\\) such that \\(g_j(\\mathbf{x}) = 0\\) for all \\(\\mathbf{x} in C^j_T\\). Perform the same computation described abov, to refine \\(C^j_T\\) such that one-dimensional components are graphs of continuous, monotone functions and repeat with \\(C^j_B\\). As before, a set of refinement poits \\[ b_{j,1}, \\ldots, b_{j,r_j} \\] is obtained When the process terminates, the union of sets of refinement points \\[ \\{b_{\\alpha + 1,1}, \\ldots, b_{\\alpha + 1,r_{\\alpha + 1}}\\}, \\ldots, \\{b_{n,1}, \\ldots, b_{n,r_n}\\} \\] forms the refinement of \\(C\\) into two- and one-dimensional monotone cells. References "],["7.3-implementation-details.html", "7.3 Implementation Details", " 7.3 Implementation Details We now discuss implementation details of this step of the algorithm. First psuedocode is presented. 7.3.1 Algorithm Input: \\[({\\cal E}, {\\cal A})\\] \\(\\cal E\\): a cylindrical algebraic decomposition of \\(\\mathbb{R}^{k+n}\\), such that each cell is the graph of a quasi-affine map. Each cell \\(C\\) of \\(\\cal E\\) has a truth-value (true or false attached. \\({\\cal A} = {\\cal A}_1,\\ldots,{\\cal A}_{k+n}\\) is the family of projection polynomials where each \\({\\cal A}_i \\subset \\mathbb{Z}[x_1,\\ldots,x_i]\\). Output: \\[ {\\cal R} := \\{ {\\cal R}_{\\mathbf{b}} = \\{ c_1,\\ldots,c_t \\} \\subset \\mathbb{A}\\mid \\mathbf{b} \\in \\mathbb{R}^{k-1} \\text{ is a } (0,\\ldots,0) \\text{-cell in the decomposition induced by } {\\cal E} \\text{ on } \\mathbb{R}^k \\} \\] such that, for each \\({\\cal R}_\\mathbf{b}\\), intersecting the sub-cad \\(\\cal D\\) above \\(\\mathbf{b}\\) with straight lines and half-planes of the kind \\(\\{x_1 &lt; c_i \\}, \\{x_1 = c_i \\}, \\{x_1 &gt; c_i\\}, 1 \\le i \\le t\\) results in a refinement of \\(\\cal D\\) such that each true cell of \\(\\cal D\\) with dimension at most \\(2\\) is monotone. First, define a subroutine \\[{\\rm sub}_{\\mathbf{y}} (g) \\mid g \\in \\mathbb{Z}[y_1,\\ldots,y_m,x_1,\\ldots,x_n], \\mathbf{y} \\in \\mathbb{A}^m, n &gt; 0,\\] which computes \\(h := g(\\mathbf{y}) \\in \\mathbb{A}[x_{1},\\ldots,x_m]\\) and returns the normalised polynomial of \\(h\\), in \\(\\mathbb{Z}[x_{m+1},\\ldots,x_n]\\) (see Section 7.1.3). It will be convenient to overload this operator and write \\({\\rm sub}_{\\mathbf{y}} (L)\\), where \\(L\\) is a set (or list) of polynomials to mean \\(\\{ {\\rm sub}_{\\mathbf{y}} (g) \\mid g \\in L \\}\\). Now define a structure to store refinement polynomials \\[ {\\cal F} := \\{ {\\cal F}_{\\mathbf{b}} := \\emptyset \\mid \\mathbf{b} \\in \\mathbb{R}^{k-1}, k &gt; 0 \\text{ is a } (0,\\ldots,0) \\text{-cell in the decomposition induced by } {\\cal E} \\text{ on } \\mathbb{R}^{k-1} \\} \\] and a similar structure to store refinement points \\[ {\\cal R} := \\{ {\\cal R}_{\\mathbf{b}} := \\emptyset \\mid \\mathbf{b} \\in \\mathbb{R}^{k-1}, k &gt; 0 \\text{ is a } (0,\\ldots,0) \\text{-cell in the decomposition induced by } {\\cal E} \\text{ on } \\mathbb{R}^{k-1} \\} \\] (Note: for each \\((0,\\ldots,0)\\)-cell \\(\\mathbf{b}\\), \\({\\cal F}_\\mathbf{b}\\) is a set of univariate polynomials, \\({\\cal R}_{\\mathbf{b}}\\) is the set of roots of polynomials \\({\\cal F}_\\mathbf{b}\\). When \\(k=1\\), then the CAD of \\(\\mathbb{R}^0\\) consisting of the unique point of \\(\\mathbb{R}^0\\) is used – practically speaking, we work directly with the CAD \\(\\cal E\\).) Let \\(\\mathbf{b}\\) be a \\((0,\\ldots,0)\\)-cell of the decomposition induced by \\(\\cal E\\) on \\(\\mathbb{R}^{k-1}, k &gt; 0\\). Let \\(\\cal D\\) be the sub-decomposition of \\(\\mathbb{R}^n\\) of \\(\\cal E\\) above \\(\\mathbf{b}\\). Consider each cell \\(C\\) of \\(\\cal D\\) with truth value true. Let \\(C\\) have index \\[ (0,\\ldots,0,1,i_{k+1},\\ldots,i_{k+n}) \\] in \\(\\cal E\\). If \\(i_{k+1} + \\cdots + i_n &gt; 2\\), then \\(\\dim(C) &gt; 2\\) and the algorithm will fail. Otherwise, let \\(\\alpha\\) be the smallest among \\(x+1,\\ldots,k+n\\) such that \\(i_{k+1} = \\ldots = i_{\\alpha - 1} = 0\\) and \\(i_\\alpha = 1\\). Then: Let \\(\\mathbf{b} := {\\operatorname{proj}_{\\mathbb{R}^{k-1}}}(C)\\), (Note: observe that \\(\\mathbf{b} \\in A^{k-1}\\). If \\(k = 1\\), then \\(\\mathbf{b}\\) is the unique cell, \\(\\mathbf{0}\\), in the CAD of \\(\\mathbb{R}^0\\). In this case, it is clear that \\({\\rm sub}_\\mathbf{0} (g) \\equiv g\\).) \\(C&#39;&#39; (C&#39;&#39;_B, C&#39;&#39;_T) \\subset \\mathbb{A}:= {\\operatorname{proj}_{\\mathbb{R}^{k}}}(C)\\), \\({\\cal G} := {\\rm sub}_{\\mathbf{b}} \\{ g_i \\mid k+1 \\le i \\le \\alpha - 1, g_i \\in {\\cal A}_i, g_i(\\mathbf{x}) = 0 \\ \\forall \\mathbf{x} \\in {\\operatorname{proj}_{\\mathbb{R}^{\\alpha-1}}}(C) \\}\\), \\(C&#39; := {\\operatorname{proj}_{\\mathbb{R}^{\\alpha}}}(C)\\). \\(C&#39;_T\\) and \\(C&#39;_B\\) be the top and bottom, respectively, \\(C&#39;\\). (Note: If \\(C&#39;\\) is not bounded from above (resp. below) by a continuous definable function, i.e., there is no section above (resp. below) \\(C&#39;\\), then let \\(C&#39;_T := \\emptyset\\) (resp \\(C&#39;_B\\)) and skip any computations involving \\(C&#39;_T\\) (resp \\(C&#39;_B\\)).) Let \\(j = \\alpha\\) and do: **(*)** For \\(\\delta \\in \\{B, T\\}\\), if \\(C_\\delta\\) is not empty, do: Let \\({\\rm sub}_{\\mathbf{b}} (g_j) \\in \\mathbb{Z}[x_{k+1,\\ldots,x_j}]\\) be such that \\(g_\\alpha(\\mathbf{x}) = 0\\) for all $ \\(C&#39;_\\delta\\). Compute \\[ f_\\delta := \\det\\begin{pmatrix}\\dfrac{\\partial g_{k+1}}{\\partial x_{k}} &amp; \\cdots &amp; \\dfrac{\\partial g_{j-1}}{\\partial x_{k}} &amp; \\dfrac{\\partial g_{j}}{\\partial x_{k}}\\\\ \\vdots &amp; &amp; &amp; \\vdots\\\\ \\dfrac{\\partial g_{k+1}}{\\partial x_{j-1}} &amp; \\cdots &amp; \\dfrac{\\partial g_{j-1}}{\\partial x_{j-1}} &amp; \\dfrac{\\partial g_{j}}{\\partial x_{j-1}} \\end{pmatrix}, \\] from Equation (7.6), using constraints \\(g_{k+1},\\ldots,g_{\\alpha+1}\\), and discarding denominators \\(\\partial g_\\alpha / \\partial x_\\alpha\\) of the total derivatives in the last column. Let \\[{\\cal H} := \\{ g_{k+1},\\ldots,g_{j-1}, f_B, f_T \\}\\] be a set of polynomials and compute \\[ {\\cal F}_{\\mathbf{b}} := {\\cal F}_{\\mathbf{b}} \\cup {\\operatorname{proj}_{\\mathbb{R}^{1}}}({\\cal H}) \\subset \\mathbb{Z}[x_k]. \\] If \\(j &lt; n\\), then Add \\(g_j\\) to \\(\\cal G\\), i.e., let \\[ {\\cal G} := {\\cal G} \\cup \\{ g_j \\}. \\] Let \\(j := j+1\\). Let \\[ C&#39; := {\\operatorname{proj}_{\\mathbb{R}^{j}}}(C) \\] \\(C&#39;\\) is a section cell, and its top and bottom may not be graphs of continuous functions. Use QE to compute \\[ ... \\] For each \\((0,\\ldots,0)\\)-cell \\(\\mathbf{b} \\in \\mathbb{A}^k\\), consider \\[ {\\cal F}_{\\mathbf{b}} \\in {\\cal F} \\in \\mathbb{Z}[k], \\] compute \\[ {\\cal R}_{\\mathbf{b}} := (c_1,\\ldots,c_t) \\] by isolating the real roots of polynomials in \\({\\cal F}_{\\mathbf{b}}\\). Return the family \\({\\cal R}\\) of refinement points. TODO - what if \\(f_j\\) does not exist - what if \\(\\alpha = k+1\\) "],["7.4-computing-the-refinements.html", "7.4 Computing the refinements", " 7.4 Computing the refinements We now describe how to refine the CAD \\(\\cal D\\) to be compatible with the refinement points in \\(\\cal R\\). For \\(0 \\le k \\le n\\), consider each refinemen point \\(\\mathbf{c} = (c_1,\\ldots,c_{k-1}, c_k) \\in {\\cal R}_k\\). It is important to note that refinement points appear in ascending order. Let \\({\\cal D}&#39;\\) be the sub-cad of \\(\\mathbb{R}^{n-k}\\) above \\((c_1,\\ldots,c_k)\\), which is a \\((0,\\ldots,0)\\)-cell of the CAD induced by \\(\\cal D\\) on \\(\\mathbb{R}^k\\) and let \\({\\cal D}&#39;&#39;\\) be the CAD induced by \\({\\cal D}&#39;\\) on \\(\\mathbb{R}^{k+1}\\). We want to refine \\({\\cal D}&#39;&#39;\\) such that \\(\\mathbf{c}\\) is a new \\((0)\\)-cell. We need only to consider coordinate \\(k+1\\) of \\(\\mathbf{c}\\). Denote it by \\(c_{k+1}\\). For each \\((0)\\)-cell \\(b_{k+1}\\) of \\({\\cal D}&#39;&#39;\\), compute \\(s := \\sign(b_{k+1} - c_{k+1})\\). If \\(s \\le 0\\), consider the next \\((0)\\)-cell in \\({\\cal D}&#39;&#39;\\). Otherwise, \\(s &gt; 0\\) and there is a \\((1)\\)-cell \\(C\\) in \\({\\cal D}&#39;&#39;\\) such that \\(c_{k+1} \\in C\\). This is the cell we need to refine. Make two new copies of \\(C\\), so that we have three identical cells \\(C_1,C_2,C_3\\). Recall that, to each cell belongs a sample point and possibly some other information. E.g., in QEPCAD, each cell has a set of signs of projection factors, which should remain unchanged, and a positional index which describes where in the CAD the cell can be found. Let \\(C_1\\) have positional index \\((j_1,\\ldots,j_k,j_{k+1})\\). New cells \\(C_2\\) and \\(C_3\\) should have positional indeices \\((j_1,\\ldots,j_k,j_{k+1} + 1\\) and \\((j_1,\\ldots,j_k,j_{k+1}+2)\\) respectively. For each eisting cell with positional index \\((l_1,\\ldots,l_k,l_{k+1})\\) with \\(l_k+1 &gt; j_{k+1}\\), the index should be updated to \\((l_1,\\ldots,l_k,l_{k+1} + 2\\). We now need to update the sample points. The sample point of the sector cell \\(C_2\\) should be \\(\\mathbf{c}\\). This might turn out to be the case by chance. In this case, there is nothing to be done with \\(C_2\\) and the sample points of sector cells \\(C_1\\) and \\(C_3\\) are incorrect. Otherwise, \\(c_{k+1}\\) is either an element of \\(C_1\\) (sample point of \\(C_1\\) is already correct) or \\(c_{k+1}\\) is an element of \\(C_3\\) (sample point of \\(C_3\\) is already correct). Let \\(C\\) be the open interval \\((a_1,a_2)\\). If the sample point of \\(C_1\\) needs to be updated, then set it to \\((a_1 + c_{k+1}) / 2\\) and if the sample point of \\(C_3\\) needs updating, then set it to \\((a_2 + c_{k+1}) / 2\\). Observe that, if we have updated the sample point of a cell \\(C\\), then the sample points of all cells in the sub-CAD above \\(C\\) are now incorrect. Since polynomials are delineable over the original cell, then they will be delineable over the smaller cells in the refinement, so we simply need to run the sample point computing part of the lifting phase recursively on the stack above \\(C\\). This involves evaluating each level \\(k+1\\) projection factor \\(f\\) ot the new sample point \\(\\mathbf{b}\\) and finding the roots of the (possibly algebraic) univariate polynomial \\(f(\\mathbf{b},x_n)\\). Repeating this process with each refinement point in \\(\\mathbf{R}_k\\), we obtain the refinement described in (Basu, Gabrielov, and Vorobjov 2015, Lemma 3.11). References "],["8-frontier-condition.html", "Chapter 8 Frontier Condition ", " Chapter 8 Frontier Condition "],["8.1-geteral-frontier-algorithm.html", "8.1 Geteral Frontier Algorithm", " 8.1 Geteral Frontier Algorithm "],["8.2-lazard-3d.html", "8.2 Lazard 3d", " 8.2 Lazard 3d "],["8.3-geteralisation-of-lazard.html", "8.3 Geteralisation of Lazard", " 8.3 Geteralisation of Lazard "],["9-notation.html", "Chapter 9 Notation", " Chapter 9 Notation For section 7.1.1: \\(C\\) is a 2-dimensional sector cell in \\(\\mathbb{R}^\\alpha\\). \\(C&#39; := {\\operatorname{proj}_{\\mathbb{R}^{\\alpha-1}}}(C)\\). \\(X := {\\operatorname{proj}_{{\\operatorname{span} \\{x_1,x_\\alpha\\}}}}(C)\\) from Theorem 7.1 \\(X&#39; := {\\operatorname{proj}_{\\mathbb{R}^{1}}}(C)\\). \\(f,g:C&#39;\\to\\mathbb{R}\\) are continuous definable functions of which \\(C_B,C_T\\) (respectively) is the graph \\(\\mathbf{h} : X&#39;\\to {\\operatorname{span} \\{x_2,\\ldots,x_{\\alpha-1}\\}}\\) is the quasi-affine map defining \\(C&#39; \\subset \\mathbb{R}^{\\alpha - 1}\\). \\(\\phi,\\psi : X&#39; \\to \\mathbb{R}\\) defines (in \\({\\operatorname{span} \\{x_1,x_\\alpha\\}}\\)) the top and bottom of \\(X\\). quantifier-free and first order formula. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
